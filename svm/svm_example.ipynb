{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"svm_example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qbltlYE_x4ZX"},"source":["<h2>개인 구글 드라이브와 colab 연동</h2>"]},{"cell_type":"code","metadata":{"id":"j6q5Z9pNGA0M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620703825874,"user_tz":-540,"elapsed":80922,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"88e25abb-8353-45ca-e9f9-1a1fceaf2b4d"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PlXCd1UpzDLL"},"source":["<h2>\"SMSSpamCollection\" 데이터를 읽고 문장과 정답을 분리하여 각 리스트에 저장</h2>\n","\n","<pre>\n","<b>1. 데이터의 형태(SMSSpamCollection)</b>\n","  라벨(스팸 또는 햄) \\t(tab) 문장 \n","  \n","  위와 같은 형태로 저장되어 있음\n","  \n","  예시)\n","    ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","    spam\\tCustomer service annoncement. You have a New Years delivery waiting for you. Please call 07046744435 now to arrange delivery\n","    ...\n","  \n","  따라서 입력 데이터를 읽고 \\t을 기준으로 입력 문장을 분리한 후에 문장과 라벨을 각각 x_data, y_data 리스트에 저장\n","  \n","<b>2. 입력 데이터 전체를 사용하지 않고 100개만 추출해서 사용</b>\n","\n","<b>3. x_data, y_data 형태</b>\n","  x_data = [ 문장1, 문장2, 문장3, ... 문장100]\n","  y_data = [ 문장1의 라벨, 문장2의 라벨, 문장3의 라벨, ... 문장100의 라벨]\n","</pre>"]},{"cell_type":"code","metadata":{"id":"gUuFzwfHGFrq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620703903564,"user_tz":-540,"elapsed":870,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"667282aa-1914-4122-bace-b0596c0be296"},"source":["import numpy as np\n","\n","file_path = \"/gdrive/My Drive/colab/svm/SMSSpamCollection\"\n","\n","# 파일 읽기\n","x_data, y_data = [], []\n","with open(file_path,'r',encoding='utf8') as inFile:\n","  lines = inFile.readlines()\n","  \n","lines = lines[:100]  \n","  \n","for line in lines:\n","  line = line.strip().split('\\t')\n","  sentence, label = line[1], line[0]\n","  x_data.append(sentence)\n","  y_data.append(label)\n","  \n","print(\"x_data의 개수 : \" + str(len(x_data)))\n","print(\"y_data의 개수 : \" + str(len(y_data)))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["x_data의 개수 : 100\n","y_data의 개수 : 100\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3R9OE2Cp1jRX"},"source":["<h2>Tokenizer 라이브러리를 사용하여 입력 문장을 index로 치환</h2>\n","\n","<pre>\n","<b>1. tokenizer.fit_on_texts(data) 함수를 이용하여 각 단어를 index로 치환하기 위한 딕셔너리 생성</b>\n","   생성된 딕셔너리는 tokenizer 객체 안에 저장됨\n","  \n","  tokenizer.fit_on_texts(data)\n","  args\n","    data : 문자열 element를 가지고 있는 리스트\n","  return\n","    X\n","    \n","  딕셔너리 예시)\n","    {'to': 1, 'i': 2, 'you': 3, 'a': 4, 'the': 5, 'and': 6, 'for': 7 ... }\n","    \n","<b>2. tokenizer.texts_to_sequences(data) 함수를 이용하여 문장 안에 있는 단어들을 index로 치환</b>\n","\n","  tokenizer.texts_to_sequence(data)\n","  args\n","    data : 문자열 element를 가지고 있는 리스트\n","  return : \n","    indexing 된 리스트\n","    \n","  indexing 예시)\n","    x_data indexing 하기 전 : Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","    x_data indexing 하기 후 : [38, 93, 239, 240, 241, 242, 53, 11, 243, 72, 94, 244, 245, 126, 246, 247, 73, 74, 248, 127]\n","    y_data indexing 하기 전 : ham\n","    y_data indexing 하기 후 : 1\n","</pre>"]},{"cell_type":"code","metadata":{"id":"L8kEaEkA02Qz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YEagO2Q0GOBM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620709706111,"user_tz":-540,"elapsed":2919,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"5cfaa5ea-da17-4cf2-cd5e-c787c0f5ea95"},"source":["from keras.preprocessing.text import Tokenizer\n","tokenizer = Tokenizer()\n","\n","# spam, ham 라벨을 대응하는 index로 치환하기위한 딕셔너리\n","label2index_dict = {'spam':0, 'ham':1}\n","\n","# indexing 한 데이터를 넣을 리스트 선언\n","indexing_x_data, indexing_y_data = [], []\n","\n","for label in y_data:\n","  indexing_y_data.append(label2index_dict[label])\n","\n","# x_data를 사용하여 딕셔너리 생성\n","tokenizer.fit_on_texts(x_data)                   \n","\n","# x_data에 있는 각 문장의 단어들을 대응하는 index로 치환하고 그 결과값을 indexing_x_data에 저장\n","indexing_x_data = tokenizer.texts_to_sequences(x_data)    \n","\n","print(\"x_data indexing 하기 전 : \" + str(x_data[0]))\n","print(\"x_data indexing 하기 후 : \" + str(indexing_x_data[0]))\n","print(\"y_data indexing 하기 전 : \" + str(y_data[0]))\n","print(\"y_data indexing 하기 후 : \" + str(indexing_y_data[0]))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["x_data indexing 하기 전 : Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","x_data indexing 하기 후 : [38, 93, 239, 240, 241, 242, 53, 11, 243, 72, 94, 244, 245, 126, 246, 247, 73, 74, 248, 127]\n","y_data indexing 하기 전 : ham\n","y_data indexing 하기 후 : 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nN5GGyQI_IpT"},"source":["<h2>SVM 모델 학습</h2>\n","\n","<pre>\n","<b>1. 데이터의 문장 길이를 고정된 길이로 변환</b>\n","  예제 코드에서는 60으로 맞추어 변환\n","  \n","  문장 길이가 60 초과인 경우 뒷 부분 제거\n","  문장 길이가 60 미만인 경우 나머지 부분을 0으로 채움\n","  \n","  예시)\n","    문장 길이를 5로 맞추고자 할 경우\n","    \n","    문장 길이가 5보다 큰 경우\n","    문장 : 나는 어제 집에서 저녁으로 김치찌개를 먹었다, indexing_문장 : 38, 93, 239, 240, 241, 242\n","    38, 93, 239, 240, 241, 242 -> 38, 93, 239, 240, 241\n","    \n","    문장 길이가 5보다 작은 경우\n","    문장 : 나는 김치찌개를 좋아해, indexing_문장 : 74, 248, 127\n","    74, 248, 127 -> 74, 248, 127, 0, 0\n","    \n","<b>2. 입력 데이터를 9 대 1 비율로 나누어 학습, 평가에 사용</b>\n","  train_x = [ 문장1, 문장2, 문장3, ... 문장90]\n","  train_y = [ 문장1의 라벨, 문장2의 라벨, 문장3의 라벨, ... 문장90의 라벨]\n","  test_x = [ 문장91, 문장92, 문장93, ... 문장100]\n","  test_y = [ 문장91의 라벨, 문장92의 라벨, 문장93의 라벨, ... 문장100의 라벨]\n","  \n","<b>3. svm.fit(x, y) 함수를 사용하여 SVM 모델 학습</b>\n","  svm.fit(x, y)\n","  args\n","    x : indexing 된 문장들이 있는 리스트\n","    y : x의 각 문장에 대응하는 라벨이 있는 리스트\n","  return : \n","    X\n","</pre>"]},{"cell_type":"code","metadata":{"id":"RYNBrDnzGO-5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620709824018,"user_tz":-540,"elapsed":2133,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"34c51291-b531-49f9-e424-e1f0c0471e5d"},"source":["from sklearn.svm import SVC\n","\n","# 문장의 길이를 max_length으로 맞춰 변환\n","max_length = 60\n","for index in range(len(indexing_x_data)):\n","  length = len(indexing_x_data[index])\n","  \n","  if(length > max_length):\n","    indexing_x_data[index] = indexing_x_data[index][:max_length]\n","  elif(length < max_length):\n","    indexing_x_data[index] = indexing_x_data[index] + [0]*(max_length-length)\n","    \n","    \n","# 전체 데이터를 9:1의 비율로 나누어 학습 및 평가 데이터로 사용\n","number_of_train = int(len(indexing_x_data)*0.9)\n","\n","train_x = indexing_x_data[:number_of_train]\n","train_y = indexing_y_data[:number_of_train]\n","test_x = indexing_x_data[number_of_train:]\n","test_y = indexing_y_data[number_of_train:]\n","\n","print(\"train_x의 개수 : \" + str(len(train_x)))\n","print(\"train_y의 개수 : \" + str(len(train_y)))\n","print(\"test_x의 개수 : \" + str(len(test_x)))\n","print(\"test_y의 개수 : \" + str(len(test_y)))\n","\n","svm = SVC(kernel='linear', C=1e10)\n","svm.fit(train_x, train_y)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["train_x의 개수 : 90\n","train_y의 개수 : 90\n","test_x의 개수 : 10\n","test_y의 개수 : 10\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SVC(C=10000000000.0, break_ties=False, cache_size=200, class_weight=None,\n","    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n","    kernel='linear', max_iter=-1, probability=False, random_state=None,\n","    shrinking=True, tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"l8Ez7hULOckE"},"source":["<h2>SVM 모델을 이용한 평가</h2>\n","\n","<pre>\n","<b>1. svm.predict(data) 함수를 사용하여 SVM 모델을 이용하여 평가</b>\n","  \n","  svm.predict(data)\n","  args\n","    data : indexing 된 문장들이 있는 리스트\n","  return : \n","    입력 문장들에 대한 모델의 출력 라벨 리스트\n","    \n","<b>2. 성능 측정</b>\n","  정답 라벨과 모델의 출력 라벨을 비교하여 성능 측정\n","  \n","<b>3. tokenizer.sequences_to_texts(data) 함수를 이용하여 indexing 된 데이터를 단어로 치환</b>\n","\n","  tokenizer.sequences_to_texts(data)\n","  args\n","    data : indexing 된 리스트\n","  return : \n","    단어로 치환된 리스트\n","    \n","  예시)\n","    [38, 93, 239, 240, 241, 242, 53, 11, 243, 72, 94, 244, 245, 126, 246, 247, 73, 74, 248, 127] -> Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n","    \n","<b>4. 입력 문장에 대한 모델의 출력과 정답 출력</b>\n","\n","</pre>"]},{"cell_type":"code","metadata":{"id":"gONe3GnfGQcu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620710102214,"user_tz":-540,"elapsed":746,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"630d8dfe-e98b-4fc5-ac36-0ba014e5df0c"},"source":["predict = svm.predict(test_x)\n","\n","correct_count = 0\n","for index in range(len(predict)):\n","  if(test_y[index] == predict[index]):\n","    correct_count += 1\n","    \n","accuracy = 100.0*correct_count/len(test_y)\n","\n","\n","print(\"Accuracy: \" + str(accuracy))\n","\n","index2label = {0:\"spam\", 1:\"ham\"}\n","\n","test_x_word = tokenizer.sequences_to_texts(test_x)\n","\n","for index in range(len(test_x_word)):\n","  print()\n","  print(\"문장 : \", test_x_word[index])\n","  print(\"정답 : \", index2label[test_y[index]])\n","  print(\"모델 출력 : \", index2label[predict[index]])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Accuracy: 80.0\n","\n","문장 :  yeah do don‘t stand to close tho you‘ll catch something\n","정답 :  ham\n","모델 출력 :  spam\n","\n","문장 :  sorry to be a pain is it ok if we meet another night i spent late afternoon in casualty and that means i haven't done any of y stuff42moro and that includes all my time sheets and that sorry\n","정답 :  ham\n","모델 출력 :  spam\n","\n","문장 :  smile in pleasure smile in pain smile when trouble pours like rain smile when sum1 hurts u smile becoz someone still loves to see u smiling\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  please call our customer service representative on 0800 169 6031 between 10am 9pm as you have won a guaranteed ￡1000 cash or ￡5000 prize\n","정답 :  spam\n","모델 출력 :  spam\n","\n","문장 :  havent planning to buy later i check already lido only got 530 show in e afternoon u finish work already\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  your free ringtone is waiting to be collected simply text the password mix to 85069 to verify get usher and britney fml po box 5249 mk17 92h 450ppw 16\n","정답 :  spam\n","모델 출력 :  spam\n","\n","문장 :  watching telugu movie wat abt u\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  i see when we finish we have loads of loans to pay\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  hi wk been ok on hols now yes on for a bit of a run forgot that i have hairdressers appointment at four so need to get home n shower beforehand does that cause prob for u\n","정답 :  ham\n","모델 출력 :  ham\n","\n","문장 :  i see a cup of coffee animation\n","정답 :  ham\n","모델 출력 :  ham\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jGk8ia1cSc66"},"source":[""],"execution_count":null,"outputs":[]}]}