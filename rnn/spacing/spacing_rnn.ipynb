{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"spacing_rnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CwxKv7Np5qMj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623628945999,"user_tz":-540,"elapsed":22241,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"8d586ca1-2fb5-46d1-a70a-ed084dcf3687"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aY7_UjO06Emi","executionInfo":{"status":"ok","timestamp":1623628952126,"user_tz":-540,"elapsed":4237,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}}},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import (DataLoader, TensorDataset)\n","from sklearn.metrics import accuracy_score\n","\n","class SpacingRNN(nn.Module):\n","\n","    def __init__(self, config):\n","        super(SpacingRNN, self).__init__()\n","\n","        # 전체 음절 개수\n","        self.eumjeol_vocab_size = config[\"eumjeol_vocab_size\"]\n","\n","        # 음절 임베딩 사이즈\n","        self.embedding_size = config[\"embedding_size\"]\n","\n","        # RNN 히든 사이즈\n","        self.hidden_size = config[\"hidden_size\"]\n","\n","        # 분류할 라벨의 개수\n","        self.number_of_labels = config[\"number_of_labels\"]\n","\n","        # 임베딩층: 랜덤 초기화 후 fine-tuning\n","        self.embedding = nn.Embedding(num_embeddings=self.eumjeol_vocab_size, embedding_dim=self.embedding_size, padding_idx=0)\n","\n","        self.dropout = nn.Dropout(config[\"dropout\"])\n","\n","        # RNN layer\n","        #self.bi_gru = nn.GRU(input_size=self.embedding_size, hidden_size=self.hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","        self.bi_lstm = nn.LSTM(input_size=self.embedding_size, hidden_size=self.hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        # fully_connected layer를 통하여 출력 크기를 number_of_labels에 맞춰줌\n","        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_labels)\n","        self.linear = nn.Linear(in_features=self.hidden_size * 2, out_features=self.number_of_labels)\n","\n","    def forward(self, inputs):\n","        # (batch_size, max_length) -> (batch_size, max_length, embedding_size)\n","        eumjeol_inputs = self.embedding(inputs)\n","\n","        # hidden_outputs, hidden_states = self.bi_gru(eumjeol_inputs)\n","        hidden_outputs, hidden_states = self.bi_lstm(eumjeol_inputs)\n","\n","        # (batch_size, max_length, hidden_size*2)\n","        hidden_outputs = self.dropout(hidden_outputs)\n","\n","        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_labels)\n","        hypothesis = self.linear(hidden_outputs)\n","\n","        return hypothesis"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"unh9In2q6OQK","executionInfo":{"status":"ok","timestamp":1623628955850,"user_tz":-540,"elapsed":302,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}}},"source":["# 데이터를 읽어 리스트에 저장\n","def read_datas(file_path):\n","    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n","        lines = inFile.readlines()\n","    datas = []\n","    for line in lines:\n","        # 입력 문장을 \\t으로 분리\n","        pieces = line.strip().split(\"\\t\")\n","        # 입력 문자열을 음절 단위로 분리\n","        eumjeol_sequence, label_sequence = pieces[0].split(), pieces[1].split()\n","        datas.append((eumjeol_sequence, label_sequence))\n","    return datas\n","\n","# 데이터를 읽고 각각의 딕셔너리 생성\n","def read_vocab_data(eumjeol_vocab_data_path):\n","    label2idx, idx2label = {\"<PAD>\":0, \"B\":1, \"I\":2}, {0:\"<PAD>\", 1:\"B\", 2:\"I\"}\n","    eumjeol2idx, idx2eumjeol = {}, {}\n","\n","    with open(eumjeol_vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n","        lines = inFile.readlines()\n","\n","    for line in lines:\n","        eumjeol = line.strip()\n","        eumjeol2idx[eumjeol] = len(eumjeol2idx)\n","        idx2eumjeol[eumjeol2idx[eumjeol]] = eumjeol\n","\n","    return eumjeol2idx, idx2eumjeol, label2idx, idx2label\n","\n","def load_dataset(config):\n","    datas = read_datas(config[\"input_data\"])\n","    eumjeol2idx, idx2eumjeol, label2idx, idx2label = read_vocab_data(config[\"eumjeol_vocab\"])\n","\n","    # 음절 데이터, 각 데이터의 실제 길이, 라벨 데이터를 담을 리스트\n","    eumjeol_features, eumjeol_feature_lengths, label_features = [], [], []\n","\n","    for eumjeol_sequence, label_sequence in datas:\n","        eumjeol_feature = [eumjeol2idx[eumjeol] for eumjeol in eumjeol_sequence]\n","        label_feature = [label2idx[label] for label in label_sequence]\n","\n","        # 음절 sequence의 실제 길이\n","        eumjeol_feature_length = len(eumjeol_feature)\n","\n","        # 모든 입력 데이터를 고정된 길이로 맞춰주기 위한 padding 처리\n","        eumjeol_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n","        label_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n","\n","        # 변환한 데이터를 각 리스트에 저장\n","        eumjeol_features.append(eumjeol_feature)\n","        eumjeol_feature_lengths.append(eumjeol_feature_length)\n","        label_features.append(label_feature)\n","\n","    # 변환한 데이터를 Tensor 객체에 담아 반환\n","    eumjeol_features = torch.tensor(eumjeol_features, dtype=torch.long)\n","    eumjeol_feature_lengths = torch.tensor(eumjeol_feature_lengths, dtype=torch.long)\n","    label_features = torch.tensor(label_features, dtype=torch.long)\n","\n","    return eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBfpm6Ts6Reg","executionInfo":{"status":"ok","timestamp":1623628960134,"user_tz":-540,"elapsed":313,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}}},"source":["def train(config):\n","    # RNN 모델 객체 생성\n","    model = SpacingRNN(config).cuda()\n","\n","    # 데이터 읽기\n","    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config)\n","\n","    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n","    train_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n","    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n","\n","    # 크로스엔트로피 비용 함수, padding은 계산하지 않음\n","    loss_func = nn.CrossEntropyLoss(ignore_index=0)\n","\n","    # 모델 학습을 위한 optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    for epoch in range(config[\"epoch\"]):\n","\n","        model.train()\n","        costs = []\n","\n","        for step, batch in enumerate(train_dataloader):\n","\n","            # 역전파 단계를 실행하기 전에 변화도를 0으로 변경\n","            optimizer.zero_grad()\n","\n","            batch = tuple(t.cuda() for t in batch)\n","\n","            # 음절 데이터, 각 데이터의 실제 길이, 라벨 데이터\n","            inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n","\n","            # 모델 출력 결과 얻어오기\n","            hypothesis = model(inputs)\n","\n","            # hypothesis : (batch_size, max_length, number_of_labels) -> (batch_size*max_length, number_of_labels)\n","            # labels : (batch_size, max_length) -> (batch_size*max_length, )\n","            cost = loss_func(hypothesis.reshape(-1, len(label2idx)), labels.flatten())\n","            cost.backward()\n","            optimizer.step()\n","\n","            # batch 단위 cost 값 저장\n","            costs.append(cost.data.item())\n","\n","        torch.save(model.state_dict(), os.path.join(output_dir, \"epoch_{0:d}.pt\".format(epoch + 1)))\n","\n","        # epoch 별로 평균 loss 값과 정확도 출력\n","        print(\"Average cost : {}\".format(np.mean(costs)))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-A9SurF6UgG","executionInfo":{"status":"ok","timestamp":1623628963736,"user_tz":-540,"elapsed":311,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}}},"source":["# 모델 출력 라벨 sequence와 정답 라벨 sequence를 기반으로\n","# 모델 출력 문장과 정답 문장 출력\n","def make_sentence(inputs, predicts, labels, idx2eumjeol, idx2label):\n","\n","    predict_sentence, correct_sentence = \"\", \"\"\n","\n","    for index in range(len(inputs)):\n","        eumjeol = idx2eumjeol[inputs[index]]\n","        correct_label = idx2label[labels[index]]\n","        predict_label = idx2label[predicts[index]]\n","\n","        # 시작 음절인 경우 공백을 추가해줄 필요가 없음\n","        if (index == 0):\n","            predict_sentence += eumjeol\n","            correct_sentence += eumjeol\n","            continue\n","\n","        # \"B\" 태그인 경우 어절의 시작 음절이므로 앞에 공백을 추가\n","        if (predict_label == \"B\"):\n","            predict_sentence += \" \"\n","        predict_sentence += eumjeol\n","\n","        # \"B\" 태그인 경우 어절의 시작 음절이므로 앞에 공백을 추가\n","        if (correct_label == \"B\"):\n","            correct_sentence += \" \"\n","        correct_sentence += eumjeol\n","\n","    return predict_sentence, correct_sentence\n","\n","# 텐서를 리스트로 변환하는 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","def test(config):\n","    # 데이터 읽기\n","    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config)\n","\n","    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n","    test_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n","    test_dataloader = DataLoader(test_features, shuffle=False, batch_size=1)\n","\n","    # RNN 모델 객체 생성\n","    model = SpacingRNN(config).cuda()\n","    # 사전학습한 모델 파일로부터 가중치 불러옴\n","    model.load_state_dict(torch.load(os.path.join(config[\"output_dir_path\"], config[\"model_name\"])))\n","\n","    # 모델의 출력 결과와 실제 정답값을 담을 리스트\n","    total_hypothesis, total_labels = [], []\n","\n","    for step, batch in enumerate(test_dataloader):\n","\n","        model.eval()\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        # 음절 데이터, 각 데이터의 실제 길이, 라벨 데이터\n","        inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n","\n","        # 모델 평가\n","        hypothesis = model(inputs)\n","\n","        # (batch_size, max_length, number_of_labels) -> (batch_size, max_length)\n","        hypothesis = torch.argmax(hypothesis, dim=-1)\n","\n","        # batch_size가 1이기 때문\n","        input_length = tensor2list(input_lengths[0])\n","        input = tensor2list(inputs[0])[:input_length]\n","        label = tensor2list(labels[0])[:input_length]\n","        hypothesis = tensor2list(hypothesis[0])[:input_length]\n","\n","        # 출력 결과와 정답을 리스트에 저장\n","        total_hypothesis += hypothesis\n","        total_labels += label\n","\n","        if (step < 10):\n","            # 정답과 모델 출력 비교\n","            predict_sentence, correct_sentence = make_sentence(input, hypothesis, label, idx2eumjeol, idx2label)\n","            print(\"정답 : \" + correct_sentence)\n","            print(\"출력 : \" + predict_sentence)\n","            print()\n","\n","    # 정확도 출력\n","    print(\"Accuracy : {}\".format(accuracy_score(total_labels, total_hypothesis)))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kj-JT2466U9u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623629317879,"user_tz":-540,"elapsed":23727,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"4549605e-6f7c-43d6-e632-ca9e408bd5e0"},"source":["if(__name__==\"__main__\"):\n","    root_dir = \"/gdrive/My Drive/colab/rnn/spacing\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\"mode\": \"train\",\n","              \"model_name\":\"epoch_{0:d}.pt\".format(5),\n","              \"input_data\":os.path.join(root_dir, \"train.txt\"),\n","              \"output_dir_path\":output_dir,\n","              \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n","              \"label_vocab\": os.path.join(root_dir, \"label_vocab.txt\"),\n","              \"eumjeol_vocab_size\": 2458,\n","              \"embedding_size\": 100,\n","              \"hidden_size\": 100,\n","              \"max_length\": 920,\n","              \"number_of_labels\": 3,\n","              \"epoch\":5,\n","              \"batch_size\":64,\n","              \"dropout\":0.3\n","              }\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Average cost : 0.5783174822602091\n","Average cost : 0.28515324826481975\n","Average cost : 0.22324668927283225\n","Average cost : 0.19196745904186105\n","Average cost : 0.17168690132189401\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1BA8wtxg6Y9R"},"source":[""],"execution_count":null,"outputs":[]}]}