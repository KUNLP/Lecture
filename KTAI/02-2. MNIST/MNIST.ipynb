{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NweRDah96YQv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.689514554983E12,
     "user_tz": -540.0,
     "elapsed": 21677.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "9c07dca5-f53d-4694-f660-adb0bc8a0d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vUxPjLIX6aDX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.689514568587E12,
     "user_tz": -540.0,
     "elapsed": 11044.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "from keras.datasets import mnist\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super(MNIST, self).__init__()\n",
    "\n",
    "    # 입력층 노드 수\n",
    "    self.inode = config[\"input_node\"]\n",
    "    # 은닉층 데이터 크기\n",
    "    self.hnode = config[\"hidden_node\"]\n",
    "    # 출력층 노드 수: 분류해야 하는 레이블 수\n",
    "    self.onode = config[\"output_node\"]\n",
    "\n",
    "    # 활성화 함수로 Sigmoid 사용\n",
    "    self.activation = nn.Sigmoid()\n",
    "\n",
    "    # 신경망 설계\n",
    "    self.linear1 = nn.Linear(self.inode, self.hnode, bias=True)\n",
    "    self.linear2 = nn.Linear(self.hnode, self.onode, bias=True)\n",
    "\n",
    "  def forward(self, input_features):\n",
    "\n",
    "    output1 = self.linear1(input_features)\n",
    "    hypothesis1 = self.activation(output1)\n",
    "\n",
    "    output2 = self.linear2(hypothesis1)\n",
    "    hypothesis2 = self.activation(output2)\n",
    "\n",
    "    return hypothesis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x8I0N67i6jzk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.689514568588E12,
     "user_tz": -540.0,
     "elapsed": 13.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 읽기 함수\n",
    "def load_dataset():\n",
    "\n",
    "  (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "  print(train_X.shape) # (60000, 28, 28)\n",
    "  print(train_y.shape) # (60000,10)\n",
    "  print(test_X.shape) # (10000, 28, 28)\n",
    "  print(test_y.shape) # (10000,10)\n",
    "\n",
    "  train_X = train_X.reshape(-1, 28*28)\n",
    "  print(train_X.shape)\n",
    "  test_X  = test_X.reshape(-1, 28*28)\n",
    "\n",
    "  train_X = torch.tensor(train_X, dtype=torch.float)\n",
    "  train_y = torch.tensor(train_y, dtype=torch.long)\n",
    "  test_X = torch.tensor(test_X, dtype=torch.float)\n",
    "  test_y = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "  return (train_X, train_y), (test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jMnZp27Y6lDS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.689514571385E12,
     "user_tz": -540.0,
     "elapsed": 2.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가 결과 계산을 위해 텐서를 리스트로 변환하는 함수\n",
    "def tensor2list(input_tensor):\n",
    "    return input_tensor.cpu().detach().numpy().tolist()\n",
    "\n",
    "# 평가 수행 함수\n",
    "def do_test(model, test_dataloader):\n",
    "\n",
    "  # 평가 모드 셋팅\n",
    "  model.eval()\n",
    "\n",
    "  # Batch 별로 예측값과 정답을 저장할 리스트 초기화\n",
    "  predicts, golds = [], []\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "      # .cuda()를 통해 메모리에 업로드\n",
    "      batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "      input_features, labels = batch\n",
    "      hypothesis = model(input_features)\n",
    "\n",
    "      # ont-hot 표현으로 변경\n",
    "      logits = torch.argmax(hypothesis,-1)\n",
    "\n",
    "      x = tensor2list(logits)\n",
    "      y = tensor2list(labels)\n",
    "\n",
    "      # 예측값과 정답을 리스트에 추가\n",
    "      predicts.extend(x)\n",
    "      golds.extend(y)\n",
    "\n",
    "    print(\"PRED=\",predicts)\n",
    "    print(\"GOLD=\",golds)\n",
    "    print(\"Accuracy= {0:f}\\n\".format(accuracy_score(golds, predicts)))\n",
    "\n",
    "# 모델 평가 함수\n",
    "def test(config):\n",
    "\n",
    "  model = MNIST(config).cuda()\n",
    "\n",
    "  # 저장된 모델 가중치 로드\n",
    "  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"])))\n",
    "\n",
    "  # 데이터 load\n",
    "  (_, _), (features, labels) = load_dataset()\n",
    "\n",
    "  test_features = TensorDataset(features, labels)\n",
    "  test_dataloader = DataLoader(test_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
    "\n",
    "  do_test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8WQcHmuQ6nMO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.68951457939E12,
     "user_tz": -540.0,
     "elapsed": 351.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train(config):\n",
    "\n",
    "  # 모델 생성\n",
    "  model = MNIST(config).cuda()\n",
    "\n",
    "  # 데이터 읽기\n",
    "  (input_features, labels), (_, _) = load_dataset()\n",
    "\n",
    "  # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n",
    "  train_features = TensorDataset(input_features, labels)\n",
    "  train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
    "\n",
    "\n",
    "  # 크로스엔트로피 비용 함수\n",
    "  loss_func = nn.CrossEntropyLoss()\n",
    "  # 옵티마이저 함수 (역전파 알고리즘을 수행할 함수)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n",
    "\n",
    "  for epoch in range(config[\"epoch\"]+1):\n",
    "\n",
    "    # 학습 모드 셋팅\n",
    "    model.train()\n",
    "\n",
    "    # epoch 마다 평균 비용을 저장하기 위한 리스트\n",
    "    costs = []\n",
    "\n",
    "    for (step, batch) in enumerate(train_dataloader):\n",
    "\n",
    "      # batch = (input_features[step], labels[step])*batch_size\n",
    "      # .cuda()를 통해 메모리에 업로드\n",
    "      batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "      # 각 feature 저장\n",
    "      input_features, labels = batch\n",
    "\n",
    "      # 역전파 변화도 초기화\n",
    "      # .backward() 호출 시, 변화도 버퍼에 데이터가 계속 누적한 것을 초기화\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # H(X) 계산: forward 연산\n",
    "      hypothesis = model(input_features)\n",
    "      # 비용 계산\n",
    "      cost = loss_func(hypothesis, labels)\n",
    "      # 역전파 수행\n",
    "      cost.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # 현재 batch의 스텝 별 loss 저장\n",
    "      costs.append(cost.data.item())\n",
    "\n",
    "    # 에폭마다 평균 비용 출력하고 모델을 저장\n",
    "    print(\"Average Loss= {0:f}\".format(np.mean(costs)))\n",
    "    torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))\n",
    "    do_test(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420.0
    },
    "id": "pCrhaRTW6pG6",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.689514615449E12,
     "user_tz": -540.0,
     "elapsed": 1193.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "204c75d5-e790-4b85-f61c-f4b4c75a41ad"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4b2254a1480c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4e2d2f4a4a0d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# 모델 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# 데이터 읽기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if(__name__==\"__main__\"):\n",
    "\n",
    "    root_dir = \"/gdrive/MyDrive/02-2. MNIST\"\n",
    "    output_dir = os.path.join(root_dir, \"output\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    config = {\"mode\": \"train\",\n",
    "              \"model_name\":\"epoch_{0:d}.pt\".format(10),\n",
    "              \"output_dir\":output_dir,\n",
    "              \"input_node\":784,\n",
    "              \"hidden_node\":512,\n",
    "              \"output_node\":10,\n",
    "              \"learn_rate\":0.001,\n",
    "              \"batch_size\":32,\n",
    "              \"epoch\":10,\n",
    "              }\n",
    "\n",
    "    if(config[\"mode\"] == \"train\"):\n",
    "        train(config)\n",
    "    else:\n",
    "        test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DHkzvwa6xqv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyOIDehH9iKIzrgIeXuGLLYQ"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
