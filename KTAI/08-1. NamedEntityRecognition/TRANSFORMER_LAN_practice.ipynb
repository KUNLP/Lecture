{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F24pbMKw8uT9"
   },
   "source": [
    "<h1>개인 구글 드라이브와 colab 연동</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4X-lNQfT1D1v",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.65926077491E12,
     "user_tz": -540.0,
     "elapsed": 22521.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "5df880cf-a635-48c3-a77f-e0ee09fd6560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdbZmdUt-d8I",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450.0
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.659260845483E12,
     "user_tz": -540.0,
     "elapsed": 927.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "9a210056-22ae-45d8-a165-af1620a9b98c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"/gdrive/MyDrive/08-1.NamedEntitYRecognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfWZLECjoJkn"
   },
   "source": [
    "<h1>TRANSFORMER_LAN 모델을 이용한 개체명 인식</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5861idd25QB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TRANSFORMER_LAN(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TRANSFORMER_LAN, self).__init__()\n",
    "\n",
    "        # 전체 character 개수\n",
    "        self.character_vocab_size = config[\"character_vocab_size\"]\n",
    "\n",
    "        # character 임베딩 사이즈\n",
    "        self.embedding_size = config[\"embedding_size\"]\n",
    "\n",
    "        # 최대 길이 (character 기준)\n",
    "        self.max_length = config[\"max_length\"]\n",
    "\n",
    "        # Transformer 히든 사이즈\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "\n",
    "        # Transformer head 개수\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "\n",
    "        # Transformer layer 개수\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "\n",
    "        # 분류할 라벨의 개수\n",
    "        self.num_of_labels = config[\"num_of_labels\"]\n",
    "\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "        # character index를 대응하는 벡터로 치환해주기 위한 임베딩 객체\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.character_vocab_size,\n",
    "                                      embedding_dim=self.embedding_size,\n",
    "                                      padding_idx=0)\n",
    "        # 입력 데이터의 각 character들의 위치 정보를 반영해주기 위한 임베딩 객체\n",
    "        self.position_embedding = nn.Embedding(num_embeddings=self.max_length,\n",
    "                                               embedding_dim=self.embedding_size)\n",
    "        self.embedding_layer_norm = nn.LayerNorm(normalized_shape=self.embedding_size)\n",
    "\n",
    "        # 분류할 각 라벨에 대응하는 임베딩 벡터들을 갖고 있는 행렬\n",
    "        self.label_embedding = nn.Parameter(torch.randn(size=(self.num_of_labels, self.hidden_size),\n",
    "                                                        dtype=torch.float32,\n",
    "                                                        requires_grad=True))\n",
    "        # Transformer encoder layer\n",
    "        self.first_encoder = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(\n",
    "                                                  d_model=self.hidden_size,\n",
    "                                                  nhead=self.num_heads,\n",
    "                                                  dim_feedforward=self.hidden_size,\n",
    "                                                  batch_first=True),\n",
    "                                                  num_layers=self.num_layers)\n",
    "\n",
    "        # Transformer encoder layer\n",
    "        self.second_encoder = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(\n",
    "                                                  d_model=self.hidden_size,\n",
    "                                                  nhead=self.num_heads,\n",
    "                                                  dim_feedforward=self.hidden_size,\n",
    "                                                  batch_first=True),\n",
    "                                                  num_layers=self.num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size * 2, out_features=self.hidden_size)\n",
    "\n",
    "        # Multi-head attention layer\n",
    "        self.first_multi_head_attention = Multihead_Attention(hidden_size=self.hidden_size,\n",
    "                                                              num_heads=self.num_heads,\n",
    "                                                              dropout_rate=config[\"dropout\"])\n",
    "\n",
    "        # Multi-head attention layer\n",
    "        self.second_multi_head_attention = Multihead_Attention(hidden_size=self.hidden_size,\n",
    "                                                               num_heads=1,\n",
    "                                                               dropout_rate=config[\"dropout\"])\n",
    "\n",
    "    def forward(self, inputs, positions):\n",
    "        # inputs : (batch_size, max_length)\n",
    "        # positions : (batch_size, max_length)\n",
    "\n",
    "        batch_size = inputs.size()[0]\n",
    "\n",
    "        # label_embedding : (1, num_of_labels, hidden)\n",
    "        label_embedding = self.label_embedding.clone().unsqueeze(dim=0)\n",
    "\n",
    "        # label_embedding : (batch_size, num_of_labels, hidden)\n",
    "        label_embedding = label_embedding.repeat(batch_size, 1, 1)\n",
    "\n",
    "        # character_inputs : (batch_size, max_length, embedding_size)\n",
    "        character_inputs = self.embedding(inputs) + self.position_embedding(positions)\n",
    "        character_inputs = self.embedding_layer_norm(character_inputs)\n",
    "        character_inputs = self.dropout(character_inputs)\n",
    "\n",
    "        # first_encoder_output : (batch_size, max_length, hidden_size)\n",
    "        first_encoder_output = self.first_encoder(src=character_inputs, \n",
    "                                                  src_key_padding_mask= (inputs == 0))\n",
    "\n",
    "        # first_attention_outputs : (batch_size, max_length, hidden_size)\n",
    "        first_attention_outputs, _ = self.first_multi_head_attention(queries=first_encoder_output,\n",
    "                                                                     keys=label_embedding,\n",
    "                                                                     values=label_embedding,\n",
    "                                                                     last_layer=False)\n",
    "\n",
    "        # middle_outputs : (batch_size, max_length, hidden_size*2)\n",
    "        middle_outputs = torch.cat(tensors=[first_encoder_output, first_attention_outputs], dim=-1)\n",
    "\n",
    "        # middle_outputs : (batch_size, max_length, hidden_size)\n",
    "        middle_outputs = self.linear(middle_outputs)\n",
    "\n",
    "        # second_encoder_output : (batch_size, max_length, hidden_size)\n",
    "        second_encoder_output = self.second_encoder(src=middle_outputs, \n",
    "                                                    src_key_padding_mask=(inputs == 0))\n",
    "\n",
    "        # second_attention_weights : (batch_size, max_length, num_of_labels)\n",
    "        _ , second_attention_weights = self.second_multi_head_attention(queries=second_encoder_output,\n",
    "                                                                        keys=label_embedding,\n",
    "                                                                        values=label_embedding,\n",
    "                                                                        last_layer=True)\n",
    "\n",
    "        return second_attention_weights\n",
    "\n",
    "\n",
    "class Multihead_Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_heads=1, dropout_rate=0):\n",
    "        super(Multihead_Attention, self).__init__()\n",
    "\n",
    "        # 히든 사이즈\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # head 개수\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # query, key, value를 위한 비선형 함수\n",
    "        self.query_linear = nn.Sequential(nn.Linear(self.hidden_size, self.hidden_size), nn.ReLU())\n",
    "        self.key_linear = nn.Sequential(nn.Linear(self.hidden_size, self.hidden_size), nn.ReLU())\n",
    "        self.value_linear = nn.Sequential(nn.Linear(self.hidden_size, self.hidden_size), nn.ReLU())\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, queries, keys, values, last_layer=False):\n",
    "        Q = self.query_linear(queries)  # (N, T_q, C)\n",
    "        K = self.key_linear(keys)  # (N, T_q, C)\n",
    "        V = self.value_linear(values)  # (N, T_q, C)\n",
    "\n",
    "        Q_ = torch.cat(torch.chunk(Q, self.num_heads, dim=2), dim=0)  # (h*N, T_q, C/h)\n",
    "        K_ = torch.cat(torch.chunk(K, self.num_heads, dim=2), dim=0)  # (h*N, T_q, C/h)\n",
    "        V_ = torch.cat(torch.chunk(V, self.num_heads, dim=2), dim=0)  # (h*N, T_q, C/h)\n",
    "\n",
    "        # attention_weights : (batch_size * num_heads, max_length, num_of_labels)\n",
    "        attention_weights = torch.bmm(Q_, K_.permute(0, 2, 1))\n",
    "        attention_weights = attention_weights / (K_.size()[-1] ** 0.5)\n",
    "        if(last_layer == False):\n",
    "            attention_weights = self.softmax(attention_weights)\n",
    "\n",
    "        # query_masks : (batch_size, max_length)\n",
    "        query_masks = torch.sign(torch.abs(torch.sum(queries, dim=-1)))\n",
    "        # query_masks : (batch_size * num_heads, max_length)\n",
    "        query_masks = query_masks.repeat(self.num_heads, 1)\n",
    "        # query_masks : (batch_size * num_heads, max_length, num_of_labels)\n",
    "        query_masks = torch.unsqueeze(query_masks, 2).repeat(1, 1, keys.size()[1])\n",
    "\n",
    "        # attention_weights : (batch_size * num_heads, max_length, num_of_labels)\n",
    "        attention_weights = attention_weights * query_masks\n",
    "        attention_weights = self.dropout(attention_weights)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # attention_outputs : (batch_size * num_heads, max_length, hidden_size / num_heads)\n",
    "        attention_outputs = torch.bmm(attention_weights, V_)\n",
    "        # attention_outputs : (batch_size, max_length, hidden_size)\n",
    "        attention_outputs = torch.cat(torch.chunk(attention_outputs, self.num_heads, dim=0), dim=2)\n",
    "\n",
    "        # attention_outputs : (batch_size, max_length, hidden_size)\n",
    "        # attention_weights : (batch_size * num_heads, max_length, num_of_labels)\n",
    "        return attention_outputs, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caSL4RyA1OOm"
   },
   "source": [
    "<h1>데이터 읽고 전처리 하기</h1>\n",
    "\n",
    "<pre>\n",
    "<b>1. read_data(file_path)</b>\n",
    "  \"train_datas.txt\", \"test_datas.txt\" 파일을 읽기 위한 함수\n",
    "  \n",
    "  데이터 예시)\n",
    "    골 프 ＜SP＞ 유 망 주 ＜SP＞ 정 지 호 \\t O O ＜SP＞ O O O ＜SP＞ B_PS I_PS I_PS\n",
    "  \n",
    "  read_file(file_path)\n",
    "  args\n",
    "    file_path : 읽고자 하는 데이터의 경로\n",
    "  return\n",
    "    datas : character sequence, 각 character에 대응하는 라벨 sequence를 담고 있는 리스트\n",
    "    \n",
    "    출력 예시)\n",
    "      datas = [\n",
    "        ([\"골\", \"프\", \"＜SP＞\", \"유\", \"망\", \"주\", \"＜SP＞\" \"정\", \"지\", \"호\"],\n",
    "         [\"O\", \"O\", \"＜SP＞\", \"O\", \"O\", \"O\", \"＜SP＞\", \"B_PS\", \"I_PS\", \"I_PS\"])\n",
    "\n",
    "        (...),\n",
    "        \n",
    "        ]\n",
    "      \n",
    "<b>2. read_vocab_data(vocab_data_path)</b>\n",
    "  \"character_vocab.txt\", \"label_vocab.txt\" 파일을 읽고 character와 라벨을 indexing하기 위한 딕셔너리를 생성\n",
    "   \n",
    "  read_vocab_data(vocab_data_path)\n",
    "  args\n",
    "    vocab_data_path : 어휘 파일 경로\n",
    "  return  \n",
    "    term2idx : character 또는 라벨을 대응하는 index로 치환하기 위한 딕셔너리\n",
    "    idx2term : index를 대응하는 character 또는 라벨로 치환하기 위한 딕셔너리\n",
    "\n",
    "    \n",
    "<b>3. convert_data2feature(datas, max_length, character2idx, label2idx)</b>\n",
    "  입력 데이터를 고정된 길이로 변환 후 indexing\n",
    "  Tensor로 변환\n",
    "   \n",
    "  convert_data2feature(datas, max_length, character2idx, label2idx)\n",
    "  args\n",
    "    datas : character sequence, 각 character에 대응하는 라벨 sequence를 담고 있는 리스트\n",
    "    max_length : 입력의 최대 길이\n",
    "    character2idx : character를 대응하는 index로 치환하기 위한 딕셔너리\n",
    "    label2idx : 라벨을 대응하는 index로 치환하기 위한 딕셔너리\n",
    "  return\n",
    "    character_features : index로 치환된 character sequence\n",
    "    position_features : 각 character의 위치 정보를 담고 있는 위치 sequence\n",
    "    label_features : index로 치환된 라벨 sequence\n",
    "    \n",
    "  전처리 예시)\n",
    "    datas = [([\"골\", \"프\", \"＜SP＞\", \"유\", \"망\", \"주\", \"＜SP＞\" \"정\", \"지\", \"호\"],\n",
    "            [\"O\", \"O\", \"＜SP＞\", \"O\", \"O\", \"O\", \"＜SP＞\", \"B_PS\", \"I_PS\", \"I_PS\"]),\n",
    "\n",
    "    (...),\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    사전 설정한 문장의 최대 길이를 12이라고 가정\n",
    "    \n",
    "    [\"골\", \"프\", \"＜SP＞\", \"유\", \"망\", \"주\", \"＜SP＞\" \"정\", \"지\", \"호\"] \n",
    "    ->\n",
    "    [\"골\", \"프\", \"＜SP＞\", \"유\", \"망\", \"주\", \"＜SP＞\" \"정\", \"지\", \"호\", \"＜PAD＞\", \"＜PAD＞\"]\n",
    "\n",
    "    [\"골\", \"프\", \"＜SP＞\", \"유\", \"망\", \"주\", \"＜SP＞\" \"정\", \"지\", \"호\", \"＜PAD＞\", \"＜PAD＞\"]\n",
    "    ->\n",
    "    [ 23, 2, 55, 65, 96, 12, 55, 19, 34, 5, 0, 0 ]\n",
    "    \n",
    "\n",
    "    [\"O\", \"O\", \"＜SP＞\", \"O\", \"O\", \"O\", \"＜SP＞\", \"B_PS\", \"I_PS\", \"I_PS\"]\n",
    "    ->\n",
    "    [\"O\", \"O\", \"＜SP＞\", \"O\", \"O\", \"O\", \"＜SP＞\", \"B_PS\", \"I_PS\", \"I_PS\", \"＜PAD＞\", \"＜PAD＞\"]\n",
    "\n",
    "    [\"O\", \"O\", \"＜SP＞\", \"O\", \"O\", \"O\", \"＜SP＞\", \"B_PS\", \"I_PS\", \"I_PS\", \"＜PAD＞\", \"＜PAD＞\"]\n",
    "    ->\n",
    "    [ 1, 1, 2, 1, 1, 1, 2, 3, 4, 4, 0, 0 ]    \n",
    "\n",
    "    character_features : Tensor([ 23, 2, 55, 65, 96, 12, 55, 19, 34, 5, 0, 0 ], [...], ...)\n",
    "    position_features : Tensor([0, 1, 2, 3, 4, 5, ..., ])\n",
    "    label_features : Tensor([ 1, 1, 2, 1, 1, 1, 2, 3, 4, 4, 0, 0 ], [...], ...)\n",
    " </pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOGS8rse1ZZZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 학습 or 평가 데이터를 읽어 리스트에 저장\n",
    "def read_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n",
    "        lines = inFile.readlines()\n",
    "\n",
    "    datas = []\n",
    "    for line in tqdm(lines, desc=\"read_data\"):\n",
    "        # 입력 문장을 \\t을 기준으로 분리\n",
    "        pieces = line.strip().split(\"\\t\")\n",
    "\n",
    "        # 입력 데이터를 character 단위로 분리\n",
    "        character_sequence, label_sequence = pieces[0].split(), pieces[1].split()\n",
    "\n",
    "        # character_sequence의 길이와 라벨 sequence의 길이가 동일한지 체크\n",
    "        assert len(character_sequence) == len(label_sequence)\n",
    "\n",
    "        datas.append((character_sequence, label_sequence))\n",
    "\n",
    "    return datas\n",
    "\n",
    "\n",
    "# 데이터를 읽고 각각의 딕셔너리 생성\n",
    "def read_vocab_data(vocab_data_path):\n",
    "    term2idx, idx2term = {\"<PAD>\":0}, {0:\"<PAD>\"}\n",
    "\n",
    "    with open(vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n",
    "        lines = inFile.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        term = line.strip()\n",
    "        term2idx[term] = len(term2idx)\n",
    "        idx2term[term2idx[term]] = term\n",
    "\n",
    "    return term2idx, idx2term\n",
    "\n",
    "\n",
    "# 입력 데이터 전처리\n",
    "def convert_data2feature(datas, max_length, character2idx, label2idx):\n",
    "    # character 데이터, character 위치 데이터, 라벨 데이터를 담을 리스트\n",
    "    character_features, position_features, label_features = [], [], []\n",
    "\n",
    "    for character_sequence, label_sequence in tqdm(datas, desc=\"convert_data2feature\"):\n",
    "        # 숫자를 0으로 치환\n",
    "        # 예시) 1 년 <SP> 6 개 월 -> 0 년 <SP> 0 개 월\n",
    "        character_sequence = [e if e != '<SP>' else ' ' for e in re.sub(\"[0-9]+\", \"0\", \" \".join(character_sequence)).split()]\n",
    "\n",
    "        # 사전 설정한 max_length의 길이를 갖는 numpy array 생성\n",
    "        character_feature = np.zeros(shape=(max_length), dtype=np.int)\n",
    "        position_feature = np.zeros(shape=(max_length), dtype=np.int)\n",
    "        label_feature = np.zeros(shape=(max_length), dtype=np.int)\n",
    "\n",
    "        # character sequence와 라벨 sequence의 각 값들을 index로 치환하고 위에서 생성한 numpy array에 저장\n",
    "        # 각 character의 위치 정보를 위에서 생성한 numpy array에 저장\n",
    "        for index in range(len(character_sequence[:max_length])):\n",
    "            character_feature[index] = character2idx[character_sequence[index]]\n",
    "            position_feature[index] = index\n",
    "            label_feature[index] = label2idx[label_sequence[index]]\n",
    "\n",
    "        # 변환한 데이터를 각 리스트에 저장\n",
    "        character_features.append(character_feature)\n",
    "        position_features.append(position_feature)\n",
    "        label_features.append(label_feature)\n",
    "\n",
    "    # 변환한 데이터를 Tensor 객체에 담아 반환\n",
    "    character_features = torch.tensor(character_features, dtype=torch.long)\n",
    "    position_features = torch.tensor(position_features, dtype=torch.long)\n",
    "    label_features = torch.tensor(label_features, dtype=torch.long)\n",
    "\n",
    "    return character_features, position_features, label_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urLIOIHT779c"
   },
   "source": [
    "<h1>TRANSFORMER_LAN 모델 학습</h1>\n",
    "\n",
    "<pre>\n",
    "<b>1. read_data(file_path) 함수를 사용하여 학습 및 평가 데이터 읽기</b>\n",
    "\n",
    "<b>2. read_vocab_data(vocab_data_path) 함수를 사용하여 어휘 딕셔너리 생성</b>\n",
    "\n",
    "<b>3. convert_data2feature(datas, max_length, character2idx, label2idx) 함수를 사용하여 데이터 전처리</b>\n",
    "\n",
    "<b>4. TRANSFORMER_LAN 모델 선언</b>\n",
    "\n",
    "<b>5. epoch를 돌때마다 평가 데이터를 이용하여 성능 측정 후 기존 성능보다 높은 경우에만 모델 파일 저장</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsYLc2YK8eNc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, TensorDataset, RandomSampler, SequentialSampler)\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    # 학습 데이터 읽기\n",
    "    train_datas = read_data(config[\"train_data_path\"])\n",
    "\n",
    "    # 평가 데이터 읽기\n",
    "    test_datas = read_data(config[\"test_data_path\"])\n",
    "\n",
    "    # 어휘 딕셔너리 생성\n",
    "    character2idx, idx2character = read_vocab_data(config[\"character_vocab_data_path\"])\n",
    "    label2idx, idx2label = read_vocab_data(config[\"label_vocab_data_path\"])\n",
    "\n",
    "    # 입력 데이터 전처리\n",
    "    train_character_features, train_position_features, train_label_features \\\n",
    "        = convert_data2feature(train_datas, config[\"max_length\"], character2idx, label2idx)\n",
    "    test_character_features, test_position_features, test_label_features \\\n",
    "        = convert_data2feature(test_datas, config[\"max_length\"], character2idx, label2idx)\n",
    "\n",
    "    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
    "    train_features = TensorDataset(train_character_features, train_position_features, train_label_features)\n",
    "    train_dataloader = DataLoader(train_features, sampler=RandomSampler(train_features), batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
    "    test_features = TensorDataset(test_character_features, test_position_features, test_label_features)\n",
    "    test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features), batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # TRANSFORMER_LAN 모델 객체 생성\n",
    "    model = TRANSFORMER_LAN(config).cuda()\n",
    "\n",
    "    # loss를 계산하기 위한 함수\n",
    "    loss_func = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    # 모델 학습을 위한 optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # softmax 함수\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    # 모델의 정확도를 저장하기 위한 변수\n",
    "    max_accuracy = 0\n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        model.train()\n",
    "\n",
    "        losses = []\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"epoch_{}_train\".format(epoch + 1))):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "            # character 데이터, character 위치 데이터, 라벨 데이터\n",
    "            inputs, positions, labels = batch[0], batch[1], batch[2]\n",
    "\n",
    "            # 역전파 단계를 실행하기 전에 변화도를 0으로 변경\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 학습\n",
    "            hypothesis = model(inputs, positions)\n",
    "\n",
    "            # (batch_size, max_length, num_labels) -> (batch_size*max_length, num_labels)\n",
    "            # batch_size, max_length\n",
    "            \n",
    "            # loss 계산\n",
    "            loss = loss_func(hypothesis.reshape(-1, config[\"num_of_labels\"]), labels.flatten())\n",
    "\n",
    "            # loss 값으로부터 모델 내부 각 매개변수에 대하여 gradient 계산\n",
    "            loss.backward()\n",
    "\n",
    "            # 모델 내부 각 매개변수 가중치 갱신\n",
    "            optimizer.step()\n",
    "\n",
    "            # batch 단위 loss 값 저장\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # 모델의 출력 결과와 실제 정답값을 담을 리스트\n",
    "        total_hypothesis, total_labels = [], []\n",
    "        for step, batch in enumerate(tqdm(test_dataloader, desc=\"epoch_{}_test\".format(epoch + 1))):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "            # character 데이터, character 위치 데이터, 라벨 데이터\n",
    "            inputs, positions, labels = batch[0], batch[1], batch[2]\n",
    "\n",
    "            # 모델 평가\n",
    "            hypothesis = model(inputs, positions)\n",
    "            # 모델의 출력값에 softmax와 argmax 함수를 적용\n",
    "            hypothesis = torch.argmax(softmax(hypothesis), dim=-1)\n",
    "\n",
    "            # Tensor를 리스트로 변경\n",
    "            hypothesis = hypothesis.cpu().detach().numpy().tolist()\n",
    "            positions = positions.cpu().detach().numpy().tolist()\n",
    "            labels = labels.cpu().detach().numpy().tolist()\n",
    "\n",
    "            # padding 제거\n",
    "            for index in range(len(hypothesis)):\n",
    "                length = np.count_nonzero(positions[index])+1\n",
    "                hypothesis[index] = hypothesis[index][:length]\n",
    "                labels[index] = labels[index][:length]\n",
    "\n",
    "                total_hypothesis += hypothesis[index]\n",
    "                total_labels += labels[index]\n",
    "\n",
    "        # 정확도 계산\n",
    "        accuracy = accuracy_score(total_labels, total_hypothesis)\n",
    "\n",
    "        # 현재의 정확도가 기존 정확도보다 높은 경우 모델 파일 저장\n",
    "        if (max_accuracy < accuracy):\n",
    "            max_accuracy = accuracy\n",
    "\n",
    "            torch.save(model.state_dict(), os.path.join(config[\"output_dir_path\"], \"epoch_{}.pt\".format(epoch + 1)))\n",
    "\n",
    "        # epoch 별로 평균 loss 값과 정확도 출력\n",
    "        print(\"Average loss : {},\\tAccuracy : {}\\n\".format(np.mean(losses), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20OC-TY8FIFj"
   },
   "source": [
    "<h1>TRANSFORMER_LAN 모델 평가</h1>\n",
    "\n",
    "<pre>\n",
    "<b>1. read_data(file_path) 함수를 사용하여 평가 데이터 읽기</b>\n",
    "\n",
    "<b>2. read_vocab_data(vocab_data_path) 함수를 사용하여 어휘 딕셔너리 생성</b>\n",
    "\n",
    "<b>3. convert_data2feature(datas, max_length, character2idx, label2idx) 함수를 사용하여 데이터 전처리</b>\n",
    "\n",
    "<b>4. TRANSFORMER_LAN 모델 객체 선언</b>\n",
    "\n",
    "<b>5. load_state_dict() 함수를 사용하여 학습한 모델 파일로부터 가중치를 불러옴</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORSC_y9Nto04"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, SequentialSampler, TensorDataset)\n",
    "\n",
    "\n",
    "def test(config):\n",
    "    # 평가 데이터 읽기\n",
    "    test_datas = read_data(config[\"test_data_path\"])\n",
    "\n",
    "    # 어휘 딕셔너리 생성\n",
    "    character2idx, idx2character = read_vocab_data(config[\"character_vocab_data_path\"])\n",
    "    label2idx, idx2label = read_vocab_data(config[\"label_vocab_data_path\"])\n",
    "\n",
    "    # 입력 데이터 전처리\n",
    "    test_character_features, test_position_features, test_label_features \\\n",
    "        = convert_data2feature(test_datas, config[\"max_length\"], character2idx, label2idx)\n",
    "\n",
    "    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
    "    test_features = TensorDataset(test_character_features, test_position_features, test_label_features)\n",
    "    test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features), batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # TRANSFORMER_LAN 모델 객체 생성\n",
    "    model = TRANSFORMER_LAN(config).cuda()\n",
    "    # 사전학습한 모델 파일로부터 가중치 불러옴\n",
    "    model.load_state_dict(torch.load(os.path.join(config[\"save_dir_path\"], config[\"trained_model_name\"])))\n",
    "\n",
    "    # softmax 함수\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # 모델의 출력 결과와 실제 정답값을 담을 리스트\n",
    "    total_hypothesis, total_labels = [], []\n",
    "    show_count = 0\n",
    "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"test\")):\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "        # character 데이터, character 위치 데이터, 라벨 데이터\n",
    "        inputs, positions, labels = batch[0], batch[1], batch[2]\n",
    "\n",
    "        # 모델 평가\n",
    "        hypothesis = model(inputs, positions)\n",
    "        # 모델의 출력값에 softmax와 argmax 함수를 적용\n",
    "        hypothesis = torch.argmax(softmax(hypothesis), dim=-1)\n",
    "\n",
    "        # Tensor를 리스트로 변경\n",
    "        inputs = inputs.cpu().detach().numpy().tolist()\n",
    "        hypothesis = hypothesis.cpu().detach().numpy().tolist()\n",
    "        positions = positions.cpu().detach().numpy().tolist()\n",
    "        labels = labels.cpu().detach().numpy().tolist()\n",
    "\n",
    "        # 나 는 사 과 가 좋 아 pad pad -> 0, 1, 2, 3, 4, 5, 6, 0, 0\n",
    "\n",
    "        # padding 제거 및 모델 예측 결과와 정답 비교\n",
    "        for index in range(len(hypothesis)):\n",
    "            length = np.count_nonzero(positions[index]) + 1\n",
    "            inputs[index] = inputs[index][:length]\n",
    "            hypothesis[index] = hypothesis[index][:length]\n",
    "            labels[index] = labels[index][:length]\n",
    "\n",
    "            total_hypothesis += hypothesis[index]\n",
    "            total_labels += labels[index]\n",
    "\n",
    "            if(show_count <= 10):\n",
    "                input_sequence = [idx2character[temp] for temp in inputs[index]]\n",
    "                predict_sequence = [idx2label[temp] for temp in hypothesis[index]]\n",
    "                correct_sequence = [idx2label[temp] for temp in labels[index]]\n",
    "\n",
    "                print(\"입력 : {}\".format(\" \".join(input_sequence)))\n",
    "                print(\"출력 : {}\".format(\" \".join(predict_sequence)))\n",
    "                print(\"정답 : {}\\n\".format(\" \".join(correct_sequence)))\n",
    "\n",
    "                show_count += 1\n",
    "\n",
    "    # 정확도 출력\n",
    "    print(\"Accuracy : {}\".format(accuracy_score(total_labels, total_hypothesis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbtyjwvtFxf7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.659260871395E12,
     "user_tz": -540.0,
     "elapsed": 13716.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "38480cf3-e5ce-4ed9-eea0-1c044248f1db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read_data: 100%|██████████| 1361/1361 [00:00<00:00, 66066.94it/s]\n",
      "convert_data2feature:   0%|          | 0/1361 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "convert_data2feature: 100%|██████████| 1361/1361 [00:00<00:00, 16383.15it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "test:  14%|█▎        | 3/22 [00:02<00:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 0 일 <SP> 유 통 업 계 와 <SP> 정 유 업 계 에 <SP> 따 르 면 <SP> ‘ 이 마 트 - S K ’ <SP> 간 판 을 <SP> 내 걸 ㄴ <SP> 주 유 소 가 <SP> 올 해 <SP> 안 에 <SP> 등 장 하 ㄹ <SP> 것 이 <SP> 확 실 시 되 자 <SP> 이 마 트 와 <SP> 경 쟁 관 계 에 <SP> 있 는 <SP> 롯 데 마 트 <SP> 홈 플 러 스 <SP> 등 <SP> 다 른 <SP> 대 형 <SP> 마 트 도 <SP> 매 장 <SP> 내 <SP> 주 유 소 <SP> 설 립 을 <SP> 위 하 아 <SP> 정 유 사 와 <SP> 물 밑 에 서 <SP> 활 발 하 게 <SP> 접 촉 하 고 <SP> 있 다 .\n",
      "출력 : B_DT I_DT <SP> O O O O O <SP> O O O O O <SP> O O O <SP> O O O O O B_OG I_OG O <SP> O O O <SP> O O O <SP> O O O O <SP> B_DT I_DT <SP> O O <SP> O O O O <SP> O O <SP> O O O O O <SP> O O O O <SP> O O O O O <SP> O O <SP> B_OG I_OG I_OG O <SP> O O I_OG I_PS <SP> O <SP> O O <SP> O O <SP> O O O <SP> O O <SP> O <SP> O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O O O <SP> O O O O <SP> O O O O <SP> O O O\n",
      "정답 : B_DT I_DT <SP> O O O O O <SP> O O O O O <SP> O O O <SP> O O O O O O O O <SP> O O O <SP> O O O <SP> O O O O <SP> B_DT I_DT <SP> O O <SP> O O O O <SP> O O <SP> O O O O O <SP> B_OG I_OG I_OG O <SP> O O O O O <SP> O O <SP> B_OG I_OG I_OG I_OG <SP> B_OG I_OG I_OG I_OG <SP> O <SP> O O <SP> O O <SP> B_OG I_OG O <SP> O O <SP> O <SP> O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O O O <SP> O O O O <SP> O O O O <SP> O O O\n",
      "\n",
      "입력 : 김 씨 는 <SP> 이 후 에 도 <SP> 기 초 생 활 수 급 자 나 <SP> 차 상 위 의 <SP> 등 록 과 <SP> 지 원 에 <SP> 대 하 ㄴ <SP> 설 명 을 <SP> 들 어 보 ㄴ <SP> 적 이 <SP> 없 었 다 .\n",
      "출력 : B_PS I_PS O <SP> O O O O <SP> O O O O O O O O <SP> O O O O <SP> O O O <SP> O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O <SP> O O O O\n",
      "정답 : B_PS O O <SP> O O O O <SP> O O O O O O O O <SP> O O O O <SP> O O O <SP> O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O <SP> O O O O\n",
      "\n",
      "입력 : A 사 에 <SP> 따 르 면 <SP> 두 <SP> 회 사 는 <SP> 실 제 <SP> 발 생 하 ㄴ <SP> 비 용 을 <SP> 근 거 로 <SP> 판 매 상 품 <SP> 건 당 <SP> 위 탁 수 수 료 를 <SP> 산 출 하 아 <SP> 주 고 <SP> 받 을 <SP> 예 정 이 며 , <SP> 이 는 <SP> 금 감 원 이 <SP> 발 표 하 ㄴ <SP> 합 리 적 이 ㄴ <SP> 수 준 에 서 <SP> 명 확 히 <SP> 선 정 되 ㄴ <SP> 위 탁 수 수 료 로 <SP> 보 ㄹ <SP> 수 <SP> 있 다 고 <SP> 하 ㄴ 다 .\n",
      "출력 : O O O <SP> O O O <SP> O <SP> O O O <SP> O O <SP> O O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O <SP> O O O O O O <SP> O O O O <SP> O O <SP> O O <SP> O O O O O <SP> O O <SP> O O O O <SP> O O O O <SP> O O O O O <SP> O O O O <SP> O O O <SP> O O O O <SP> O O O O O O <SP> O O <SP> O <SP> O O O <SP> O O O O\n",
      "정답 : O O O <SP> O O O <SP> O <SP> O O O <SP> O O <SP> O O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O <SP> O O O O O O <SP> O O O O <SP> O O <SP> O O <SP> O O O O O <SP> O O <SP> B_OG I_OG I_OG O <SP> O O O O <SP> O O O O O <SP> O O O O <SP> O O O <SP> O O O O <SP> O O O O O O <SP> O O <SP> O <SP> O O O <SP> O O O O\n",
      "\n",
      "입력 : 대 우 조 선 해 양 과 <SP> 만 도 , <SP> 현 대 산 업 개 발 <SP> 등 이 <SP> 전 반 적 으 로 <SP> 양 호 하 ㄴ <SP> 0 <SP> · <SP> 0 분 기 <SP> 실 적 을 <SP> 발 표 하 았 다 .\n",
      "출력 : B_OG I_OG I_OG I_OG I_OG I_OG O <SP> O O O <SP> B_OG I_OG I_OG I_OG O O <SP> O O <SP> O O O O O <SP> O O O O <SP> B_DT <SP> O <SP> O I_DT I_DT <SP> O O O <SP> O O O O O O\n",
      "정답 : B_OG I_OG I_OG I_OG I_OG I_OG O <SP> B_OG I_OG O <SP> B_OG I_OG I_OG I_OG I_OG I_OG <SP> O O <SP> O O O O O <SP> O O O O <SP> B_DT <SP> I_DT <SP> I_DT I_DT I_DT <SP> O O O <SP> O O O O O O\n",
      "\n",
      "입력 : 0 0 일 <SP> 삼 성 전 자 에 <SP> 따 르 면 <SP> 갤 럭 시 S 0 는 <SP> 독 일 <SP> 출 시 <SP> 0 주 만 에 <SP> 0 0 만 대 <SP> 이 상 <SP> 판 매 되 었 으 며 <SP> 이 에 <SP> 따 르 아 <SP> 삼 성 전 자 는 <SP> 독 일 <SP> 진 출 <SP> 이 후 <SP> 스 마 트 폰 <SP> 시 장 에 서 <SP> 가 장 <SP> 높 은 <SP> 점 유 율 이 ㄴ <SP> 0 0 . 0 % 를 <SP> 기 록 하 았 다 .\n",
      "출력 : B_DT I_DT I_DT <SP> B_OG I_OG I_OG I_OG O <SP> O O O <SP> O O O I_OG O O <SP> B_LC I_DT <SP> O O <SP> O O O O <SP> O O O O <SP> O O <SP> O O O O O O <SP> O O <SP> O O O <SP> B_OG I_OG O O O <SP> B_LC O <SP> O O <SP> O O <SP> O I_OG O O <SP> O O O O <SP> O O <SP> O O <SP> O O O O O <SP> O O O O O O <SP> O O O O O O\n",
      "정답 : B_DT I_DT I_DT <SP> B_OG I_OG I_OG I_OG O <SP> O O O <SP> O O O O O O <SP> B_LC I_LC <SP> O O <SP> B_DT I_DT O O <SP> O O O O <SP> O O <SP> O O O O O O <SP> O O <SP> O O O <SP> B_OG I_OG I_OG I_OG O <SP> B_LC I_LC <SP> O O <SP> O O <SP> O O O O <SP> O O O O <SP> O O <SP> O O <SP> O O O O O <SP> O O O O O O <SP> O O O O O O\n",
      "\n",
      "입력 : 토 요 ( 당 일 ) 0 차 <SP> 낙 동 정 맥 <SP> 종 주 대 원 <SP> 모 집\n",
      "출력 : B_OG I_OG O B_DT I_DT O O O <SP> B_OG I_OG I_OG I_OG <SP> B_OG I_OG I_OG O <SP> O O\n",
      "정답 : B_DT I_DT O B_DT I_DT O O O <SP> B_LC I_LC I_LC I_LC <SP> O O O O <SP> O O\n",
      "\n",
      "입력 : 거 기 서 <SP> 나 가 노 까 지 <SP> 교 통 비 는 <SP> 잘 <SP> 모 르 겠 음 <SP> . <SP> .\n",
      "출력 : O O O <SP> O O O O I_OG <SP> O O O O <SP> O <SP> O O O O <SP> O <SP> O\n",
      "정답 : O O O <SP> B_LC I_LC I_LC O O <SP> O O O O <SP> O <SP> O O O O <SP> O <SP> O\n",
      "\n",
      "입력 : 가 을 운 동 회 <SP> 때 마 다 <SP> 만 국 기 가 <SP> 휘 날 리 었 던 <SP> 교 정 은 <SP> 잡 초 만 <SP> 무 성 하 ㄴ <SP> 채 <SP> 황 량 하 다 .\n",
      "출력 : O O O O O <SP> O O O <SP> O O O O <SP> O O O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O <SP> O O O O O\n",
      "정답 : B_DT I_DT O O O <SP> O O O <SP> O O O O <SP> O O O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O <SP> O O O O O\n",
      "\n",
      "입력 : 솔 <SP> 향 기 <SP> 가 득 <SP> 묻 어 오 는 <SP> 바 람 이 <SP> 향 긋 하 아 <SP> 타 지 역 으 로 <SP> 떠 나 ㄹ <SP> 수 <SP> 없 다 는 <SP> 입 주 민 이 <SP> 많 을 <SP> 정 도 로 <SP> 소 나 무 <SP> 숲 이 <SP> 우 거 지 어 <SP> 있 으 며 , <SP> 낙 동 강 <SP> 너 머 로 <SP> 귀 가 를 <SP> 서 두 르 는 <SP> 저 녁 노 을 <SP> 또 한 <SP> 멋 지 ㄴ <SP> 이 곳 은 <SP> 0 개 동 <SP> 0 0 0 가 구 가 <SP> 0 0 0 0 년 에 <SP> 입 주 하 아 <SP> 이 제 <SP> 막 <SP> 0 0 년 이 <SP> 지 나 고 <SP> 있 다 <SP> .\n",
      "출력 : O <SP> O O <SP> O O <SP> O O O O <SP> O O O <SP> O O O O <SP> O O O O O <SP> O O O <SP> O <SP> O O O <SP> O O O O <SP> O O <SP> O O O <SP> O O O <SP> O O <SP> O O O O <SP> O O O O <SP> O O O <SP> O O O <SP> O O O <SP> O O O O <SP> O O O O <SP> O O <SP> O O O <SP> O O O <SP> I_DT O O <SP> I_DT O I_DT O O O <SP> I_DT I_DT I_DT I_DT I_DT O <SP> O O O O <SP> O O <SP> O <SP> I_DT I_DT I_DT O <SP> O O O <SP> O O <SP> O\n",
      "정답 : O <SP> O O <SP> O O <SP> O O O O <SP> O O O <SP> O O O O <SP> O O O O O <SP> O O O <SP> O <SP> O O O <SP> O O O O <SP> O O <SP> O O O <SP> O O O <SP> O O <SP> O O O O <SP> O O O O <SP> B_LC I_LC I_LC <SP> O O O <SP> O O O <SP> O O O O <SP> O O O O <SP> O O <SP> O O O <SP> O O O <SP> O O O <SP> O O O O O O <SP> B_DT I_DT I_DT I_DT I_DT O <SP> O O O O <SP> O O <SP> O <SP> B_DT I_DT I_DT O <SP> O O O <SP> O O <SP> O\n",
      "\n",
      "입력 : K B 투 자 증 권 은 <SP> 앞 으 로 <SP> 주 문 기 능 <SP> 및 <SP> 실 시 간 <SP> 시 세 <SP> 잔 고 , <SP> 거 래 내 역 <SP> 조 회 <SP> 등 의 <SP> 기 능 을 <SP> 단 계 적 으 로 <SP> 오 픈 <SP> 하 ㄹ <SP> 예 정 이 다 <SP> .\n",
      "출력 : B_OG I_OG I_OG I_OG I_OG I_OG O <SP> O O O <SP> O O O O <SP> O <SP> O O O <SP> O O <SP> O O O <SP> O O O O <SP> O O <SP> O O <SP> O O O <SP> O O O O O <SP> O O <SP> O O <SP> O O O O <SP> O\n",
      "정답 : B_OG I_OG I_OG I_OG I_OG I_OG O <SP> O O O <SP> O O O O <SP> O <SP> O O O <SP> O O <SP> O O O <SP> O O O O <SP> O O <SP> O O <SP> O O O <SP> O O O O O <SP> O O <SP> O O <SP> O O O O <SP> O\n",
      "\n",
      "입력 : 또 <SP> 전 남 은 <SP> 올 해 보 다 <SP> 절 반 <SP> 이 상 <SP> 떨 어 지 ㄹ <SP> 것 으 로 <SP> 전 망 되 었 다 .\n",
      "출력 : O <SP> B_OG O O <SP> B_DT I_DT O O <SP> O O <SP> O O <SP> O O O O <SP> O O O <SP> O O O O O O\n",
      "정답 : O <SP> B_LC I_LC O <SP> B_DT I_DT O O <SP> O O <SP> O O <SP> O O O O <SP> O O O <SP> O O O O O O\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 22/22 [00:03<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9190292391476762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if(__name__==\"__main__\"):\n",
    "    root_dir = \"/gdrive/MyDrive/2021 하계 강의자료/02-1. Named Entity Recognition/Practice\"\n",
    "    save_dir = os.path.join(root_dir, \"save\")\n",
    "    output_dir = os.path.join(root_dir, \"output\")\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    set_seed(seed=1234)\n",
    "\n",
    "    config = {\"mode\": \"test\",\n",
    "              \"trained_model_name\":\"epoch_{}.pt\".format(18),\n",
    "              \"train_data_path\":os.path.join(root_dir, \"train_datas.txt\"),\n",
    "              \"test_data_path\": os.path.join(root_dir, \"test_datas.txt\"),\n",
    "              \"save_dir_path\":save_dir,\n",
    "              \"output_dir_path\": output_dir,\n",
    "              \"character_vocab_data_path\": os.path.join(root_dir, \"character_vocab.txt\"),\n",
    "              \"label_vocab_data_path\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
    "              \"character_vocab_size\": 2159,\n",
    "              \"embedding_size\": 256,\n",
    "              \"hidden_size\": 256,\n",
    "              \"max_length\": 491,\n",
    "              \"learning_rate\":5e-5,\n",
    "              \"num_heads\":4,\n",
    "              \"num_layers\": 1,\n",
    "              \"num_of_labels\": 15,\n",
    "              \"epoch\":20,\n",
    "              \"batch_size\":64,\n",
    "              \"dropout\":0.3\n",
    "              }\n",
    "\n",
    "    if(config[\"mode\"] == \"train\"):\n",
    "        train(config)\n",
    "    else:\n",
    "        test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bk-3ADInQDHZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
