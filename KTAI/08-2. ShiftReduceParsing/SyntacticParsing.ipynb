{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZX_rBsT48SZf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.675671809864E12,
     "user_tz": -540.0,
     "elapsed": 26037.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "6f4bee33-19cd-4934-ab1d-62d994a5d7c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI5DaVzC8WsD"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "root_dir = \"/gdrive/MyDrive/8-2.Syntactic Parsing\"\n",
    "sys.path.append(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aUvoUrN9h68",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.675671842434E12,
     "user_tz": -540.0,
     "elapsed": 11483.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "640244d1-47e2-4ef0-a82d-d5cf4706a574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448.0
    },
    "id": "69cn7SBY8mfT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.675671848608E12,
     "user_tz": -540.0,
     "elapsed": 1053.0,
     "user": {
      "displayName": "YJ JJ",
      "userId": "16685945690070219700"
     }
    },
    "outputId": "d5bec626-e5ce-4116-855d-cd9a6fd2bddc"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": [
       "/9j/4AAQSkZJRgABAQEAYABgAAD/4RDcRXhpZgAATU0AKgAAAAgABAE7AAIAAAAKAAAISodpAAQAAAABAAAIVJydAAEAAAAIAAAQzOocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyepeyYgeynhAAABZADAAIAAAAUAAAQopAEAAIAAAAUAAAQtpKRAAIAAAADNzAAAJKSAAIAAAADNzAAAOocAAcAAAgMAAAIlgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADIwMjM6MDI6MDYgMDM6NTI6NDkAMjAyMzowMjowNiAwMzo1Mjo0OQAAAKXHAcbEyQAA/+ELHGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjMtMDItMDZUMDM6NTI6NDkuNzAyPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPuyepeyYgeynhDwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAGvAmADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6RooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPOpNW8S614d1nxRomr/ZYrCa6Ww04W8bw3SW7sjeaxUvl2jbBRl2gjg857vSr9NV0ez1GFSsd3Ak6qeoDKGA/WvO7N9S8N+EtZ8IQaLqFxqDT3g0ySO2dredLiR5EZ5gNke3zMMGIPynAORn0HRtP/snQbDTt/mfY7aODfj72xQuf0oAz9S8aaHpWoS2VzczyXEADTpaWc1z9nB5BkMSMIwRz82OOaW/8Z+H9OttNuLnUkMOq5+wvAjTC4whfC7AckqOB3OAMkgVz+j38nhHVtftNV0jU5WvtSkvra6sbGW5S5SQLhSyKdjLjbh9owAQcdMjS/DWp6fdfDyO706Rfs2paldXKIm9LNZo7h40ZhlRt8xUznGRx2oA9OtLlLyziuYVlWOVQ6iaFonAPqjgMp9iAa4fXvEfiqy+IegWC2lpZaFeai1qZTL5s93/o7yZAxiNAVx1LEjsOve1yHjKyurrxR4LltraaaO21Z5J3jjLCJfs0y7mI+6MkDJ7kUAdfRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRQTgZNedfDz4t6f498W+ItHtvLUafNmycH/j4gGFL+/zgn6OvvQB6LRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBmeJNJm13w1f6VbXz6fJeQtD9pjTc0YbhiBkc4yM9s5rxj4a/A+Pwz8QL/AFTTvEdyJND1AWuw2423Mb20MrBvm4/1xH/AQa96rm/C/wDyMXjP/sNR/wDpvs6AOkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK474keLb3wzo1pa6BAlzr+sXK2WmwyfdEh6yN/sqOT+FdjXm3jgB/jl8MEcZXdqjYPqLZSD+FAENt8DNC1OFbr4gXd/4o1aQbp57i8kjjDekaIV2qOgH/AOoTf8M+fDH/AKFn/wAn7n/45XpNFAHm3/DPnwx/6Fn/AMn7n/45R/wz58Mf+hZ/8n7n/wCOV6TRQB5t/wAM+fDH/oWf/J+5/wDjlH/DPnwx/wChZ/8AJ+5/+OV6TRQB5t/wz58Mf+hZ/wDJ+5/+OUf8M+fDH/oWf/J+5/8Ajlek0UAebf8ADPnwx/6Fn/yfuf8A45R/wz58Mf8AoWf/ACfuf/jlek0UAebf8M+fDH/oWf8Ayfuf/jlH/DPnwx/6Fn/yfuf/AI5XpNFAHm3/AAz58Mf+hZ/8n7n/AOOUf8M+fDH/AKFn/wAn7n/45XpNFAHm3/DPnwx/6Fn/AMn7n/45R/wz58Mf+hZ/8n7n/wCOV6TRQB5t/wAM+fDH/oWf/J+5/wDjlH/DPnwx/wChZ/8AJ+5/+OV6TRQB5t/wz58Mf+hZ/wDJ+5/+OUf8M+fDH/oWf/J+5/8Ajlek0UAebf8ADPnwx/6Fn/yfuf8A45R/wz58Mf8AoWf/ACfuf/jlek0UAebf8M+fDH/oWf8Ayfuf/jlH/DPnwx/6Fn/yfuf/AI5XpNFAHm3/AAz58Mf+hZ/8n7n/AOOUf8M+fDH/AKFn/wAn7n/45XpNFAHm3/DPnwx/6Fn/AMn7n/45R/wz58Mf+hZ/8n7n/wCOV6TRQB5t/wAM+fDH/oWf/J+5/wDjlH/DPnwx/wChZ/8AJ+5/+OV6TRQB5t/wz58Mf+hZ/wDJ+5/+OUf8M+fDH/oWf/J+5/8Ajlek0UAebf8ADPnwx/6Fn/yfuf8A45TX/Z/+HyLu0zTLvS7gfcubPUZxIh9QWdh+lel0UAeb+C9a17w/40n8B+M77+0pGgN3o+qMuHuoQcMkmP8Alovr3GT6Z9IrzbxqAvx4+GTKMM66qrH1AtlIH516TQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFebeNv8Aku3ww/7i3/pMtek15t42/wCS7fDD/uLf+ky0Aei3FxHa2stxcNsihQu7YJwoGScD2rhtJ+N3w91zV7XS9L8QefeXcoigi+xXC73JwBlowB+JrrPEP/Is6p/15y/+gGvH/gHr3iyPwB4d0yHwZ5uhb5wdb/tWJcKZpCzeRjfwxK4zzjNAHuNFfN03xd+IGu32qal4Zstca3tbxoLOxsfDy3dpKqEZE1xu3qxByQo449eNzxp8U/FU3jO28P6Baa1p3k6bFeXg0rR11C6EkiqdhjkICKu4Anrnj6AHutc9P41063+Ilt4MeG6Oo3Fgb9JQi+SIwzLgndndlD/DjpzXl1x8TPHLeCPDlhNYnRvE+uas2mpc6hZGHZGNuJvJboTvXjkZDYzUejWHiDTP2otMtvFetw65dr4ecx3kdqtuTGZHwGReAQ27kdsUAe7VyGh/ErSPEnjC90DRrPU7n7Czxz6itr/oayL1j8zP3vwwccGoNN8b3Xiy4v8ARdP8P+KPDl2bWXyNV1TSQsET/dVhliHIJDBTwQDXjnw51jX/AAL8N/G3iz+2FvrPT9UuIDpbWSKs92xhQXBkB3AfOMoOMDrQB9M0V4fqPiX4i+BtJ8P+KvEHiSx1vT9VuoIbnSo9PSLyFlUt+6kX5nIA7/rWhY65468SfGbxV4e0vxDBp+k6RLbSAvYxyuqlQTEvAPz/ADZYklccdaAPYKK8Ok+IPi+30/xP4ZGoJN4ri8RRabpc7wRrshn+aN2ULtIEaSHJB6jOcVd8IfEbXPF2seB7WG+Fuv8AZdxe+Ig0KAv5beSM5X5Myqx+XHB9qAPZKK+etZ+KPivQ7rStfi8UwazpV5qSWk1lb6DJFZqhJz5d26jzGwpHBPOTggV0tjrnjrxJ8ZvFXh7S/EMGn6TpEttIC9jHK6qVBMS8A/P82WJJXHHWgD1bU7+LStJvNRuFdobSB55FjALFVUsQM45wKpeFPEtn4w8L2WvaZHPFa3qF40uFCuAGK8gEjqPU145ceIPHXxB0Xxtq+k+ILLSNC0l7qxTTHsllN0scZLl5D8yEqwwR34xxk938Df8Akifhv/rg/wD6NegDf1Hxz4c0jxdY+GNS1NbfWNQRZLa3eJ8SAlgPn27QSUYAEgk/UVa1TxRo+i61pWk6neeRe6w7pYxeU7ecyYLDIBC43D7xHWvGvib4Ti8aftEWWjvO1tM3hjzbW5QkGCZJ5WR+PQj8s1mSeMLnxR8Rvhjaa5H9n8Q6PqN5Z6rbkYIkCxYkH+y4GQenXHAoA+jqK+dta+K/jrV/E3iBfCtvriW2k3clpa2+maAl9DO8Zx+/lJ3JuI6KOAe+OetsfHfii8+M3hHSL1ZNNsNU8PC9vdMkt1BS4xLuG5l3jG1eMjpyOaAPXKK8Nv8A4i+KIdC+K1xFqmJfD99HDprfZ4j9nUyFSPu/Nx/ezW5b634v0v4bDxB4k8X6Zb3WrxWZslm0/K2ZcEsoEfzTyMpB2gY3KcDFAHpmp38WlaTeajcK7Q2kDzyLGAWKqpYgZxzgVS8KeJbPxh4Xste0yOeK1vULxpcKFcAMV5AJHUeprxvS/HPiSbV/F/g/xHqkusQL4duby2vLnSG06YEJgqYSAQvzHBI7D1rvPgb/AMkT8N/9cH/9GvQBv6j458OaR4usfDGpamtvrGoIsltbvE+JASwHz7doJKMACQSfqKtap4o0fRda0rSdTvPIvdYd0sYvKdvOZMFhkAhcbh94jrXjXxN8JxeNP2iLLR3na2mbwx5trcoSDBMk8rI/HoR+WazJPGFz4o+I3wxtNcj+z+IdH1G8s9VtyMESBYsSD/ZcDIPTrjgUAfR1QT3trayQx3VzDC877IVkkCmRvRQep9hXz7rXxX8dav4m8QL4Vt9cS20m7ktLW30zQEvoZ3jOP38pO5NxHRRwD3xyvxAj8U+IPH3wv1B9VfQr3VI5GgtZNPVm0ufZEZSQ+C+4kDa2Nu33NAH0RRXiuo/EDxP4X1Hx1oWp6iL/AFK2itX0CQ28cZY3BEYwoGGCyOv3s/dPWmaD8QPFWsnwl4dbUQuv/wBuXdprkyW8fzw2p3ONpXCbldBkAHPSgD22ivCdN8V/Ebxr4P1jx3oniSx0bTbFp2ttHbT0l82OJdx8yVvmViPTj6VJqPxK8X6/efDgeGLqDS38TW05uopYFkjV1ABcbhuwvzMACM8AmgD1Gfxrp1v8RLbwY8N0dRuLA36ShF8kRhmXBO7O7KH+HHTmuhr548Z+ILz4ffGiw1fW5pNdvtP8IHzJorcRfaJDPKoYquQi5Iz2AzXsfgOLXR4Vt7rxRrcer314ouC9vHGsMKsMhIygG5QP4iSTQBzXjb/ku3ww/wC4t/6TLXpNebeNv+S7fDD/ALi3/pMtek0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXm3jb/AJLt8MP+4t/6TLXpNebeOCE+OXwwdzhd2qLk+ptlAH40Aeh3lql9Yz2kpYRzxtGxU8gMMHHvzWV4O8KWPgjwnZ+HtKluJrSz3+W9yytId7s5yVAHVj26Vt0UAed3XwU8Ozaxd3tpqOu6bb38hlvdNsNRaG1uWP3t6gZ59ARWj4s+F+jeK9ch1o32q6Nq0UXk/b9IuzbytH12k4II/DNdnRQBxerfCvw9rXg2z8OXj35hsZjcW16LpjdRzFmYyeY2csSzHkEc9OBiLQPhPo/h/wAX2/iWLU9av9ThtDavLqF4JzMCSdzkrndggcEDAHFdzRQAVyWh/DXQdD8NaxoIWe/0/WbuW7uo7xlbLSBQwBVVwBtBHcHvXW0UAec6T8EfDemalY3NxqGt6rb6a4ex0/Ur4y21qw6FEwMY7Akiuk0fwVp2ieMNc8SWk1095rflfaY5XUxp5a4GwBQR75JroqKAOSm+G2hz/EyHxy7XQ1OKIRiISL5DEIyByu3JYKxAOce1ReG/hd4f8Mavr2oWX2qZ9dLC4juJAUiRmZmSPABVSXPBJ6DmuyooA8qf9nvww+mQae+seIntLW6FzawPqAaO3IzlUQoVCktknG7gc9c9no/grTtE8Ya54ktJrp7zW/K+0xyupjTy1wNgCgj3yTXRUUAedX/wS8N3usapex32tWMOrF2vbCzvjHbTu2cuyY5OTnBO3PbHFdd4U8NWfg/wvZaDpkk8trZIUje4YM5BYtyQAOp9BWvRQBz0/grTrj4iW3jN5roajbWBsEiDr5JjLM2SNud2XP8AFjpxWbqnwt8P6r8RrDxrJ9pt9VstvEDqsc5AIBkBUkkA4yCOAPSuzooA8/1T4OaDqHiK71iz1PXNGl1B999BpWoGCK7Y9S6gE885wR1J61d8U/C7RPFN5pV691qelX2lR+VbXel3ZhlWPGNhYgnHXnryeea7OigDz22+C/huz8P+I9Gt7nU1tfETo90WnVnjKtuGxmUnk9S24n1rX8RfDrRvE3g3T/DmoS3scGmmFrS5t5gk8TxLtVw2MZwT2xz06V1dFAHnunfBnQdO1m81X+1Nbu7y+02TTria8vBM0iOMFyzLnfgDHOBjpXV+FPDVn4P8L2Wg6ZJPLa2SFI3uGDOQWLckADqfQVr0UAc9P4K064+Ilt4zea6Go21gbBIg6+SYyzNkjbndlz/FjpxWbqnwt8P6r8RrDxrJ9pt9VstvEDqsc5AIBkBUkkA4yCOAPSuzooA8/wBU+Dmg6h4iu9Ys9T1zRpdQfffQaVqBgiu2PUuoBPPOcEdSetaPjD4a6N4yt9JS6udR06fRmJsbvTrnypochQQGIb+4vPXjrXX0UAcdqvww0PWfGGieJb2W9a/0aJI4sSrtnCNuQy5XLEN83BHNSaT8NtD0b4hal4xtGum1DUVZXikkUwxFtu5kULkFtgyST3rraKAPNtQ+Bnhm9vryS31DXNOsb+UzXmlWN+YrS4Y9d0eD19iPbFb9x8OtDl17w3qkAntD4ajeKxtrdlEO1l2kMCpJwB2I9811VFAHM6h4B0fVPHUfim+M8t0umtprWzFTBJCzMTuUrkn5yOuMdqk8F+DLPwNo76VpV9f3Fj5rSQQXkiuLYE5KIQoO3J6MT/OuiooA828bf8l2+GH/AHFv/SZa9JrzbxqQ3x4+GSqcsi6qzD0BtlAP516TQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFcd8SPCV74m0a0utAnS21/R7lb3TZpPumQdY2/wBlhwfwrsaKAPMLb45aFpkK2vxAtL/wvq0Y2zwXFnJJGW9Y3QNuU9Qf/wBZm/4aD+GP/Qzf+SFz/wDG69JooA82/wCGg/hj/wBDN/5IXP8A8bo/4aD+GP8A0M3/AJIXP/xuvSaKAPNv+Gg/hj/0M3/khc//ABuj/hoP4Y/9DN/5IXP/AMbr0migDzb/AIaD+GP/AEM3/khc/wDxuj/hoP4Y/wDQzf8Akhc//G69JooA82/4aD+GP/Qzf+SFz/8AG6P+Gg/hj/0M3/khc/8AxuvSaKAPNv8AhoP4Y/8AQzf+SFz/APG6P+Gg/hj/ANDN/wCSFz/8br0migDzb/hoP4Y/9DN/5IXP/wAbo/4aD+GP/Qzf+SFz/wDG69JooA82/wCGg/hj/wBDN/5IXP8A8bo/4aD+GP8A0M3/AJIXP/xuvSaKAPNv+Gg/hj/0M3/khc//ABuj/hoP4Y/9DN/5IXP/AMbrZ+KfjWPwF8Pr/WAy/ayvkWSH+KZgQvHfHLH2U155+zP4/k17w5d+GdUuGlv9NYzwPI2Wkgdsnnvtc9T2dR2oA6r/AIaD+GP/AEM3/khc/wDxuj/hoP4Y/wDQzf8Akhc//G69JooA82/4aD+GP/Qzf+SFz/8AG6P+Gg/hj/0M3/khc/8AxuvSaKAPNv8AhoP4Y/8AQzf+SFz/APG6P+Gg/hj/ANDN/wCSFz/8br0migDzb/hoP4Y/9DN/5IXP/wAbo/4aD+GP/Qzf+SFz/wDG69JooA82/wCGg/hj/wBDN/5IXP8A8bo/4aD+GP8A0M3/AJIXP/xuvSaKAPNv+Gg/hj/0M3/khc//ABuj/hoP4Y/9DN/5IXP/AMbr0migDzb/AIaD+GP/AEM3/khc/wDxuj/hoP4Y/wDQzf8Akhc//G69JooA82/4aD+GP/Qzf+SFz/8AG6a/7QHw+ddumand6pcH7ltZ6dOZHPoAyKP1r0uigDzfwXouveIPGk/jzxnY/wBmyLAbTR9LZsvawk5Z5Mf8tG9OwyPTHpFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBVvtMsNTjWPUrK3vEQ5VbiJZAp9QCK5j4baPplr4QsLu2060huSJQZo4FVyPMbjcBntXY1zfw9/5ETT/+2v8A6NagDpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKr6hf22laZdahfyiG1tIXnnkIJ2IoLMcDngA9KsVzfxH/5JZ4r/wCwLef+iHoAP+E90b/n31z/AMJ++/8AjNH/AAnujf8APvrn/hP33/xmukooA5v/AIT3Rv8An31z/wAJ++/+M0f8J7o3/Pvrn/hP33/xmukooA5v/hPdG/599c/8J++/+M0f8J7o3/Pvrn/hP33/AMZrpKKAOb/4T3Rv+ffXP/Cfvv8A4zR/wnujf8++uf8AhP33/wAZrpKKAOb/AOE90b/n31z/AMJ++/8AjNH/AAnujf8APvrn/hP33/xmukooA5v/AIT3Rv8An31z/wAJ++/+M0f8J7o3/Pvrn/hP33/xmukooA5v/hPdG/599c/8J++/+M0f8J7o3/Pvrn/hP33/AMZrpKKAOb/4T3Rv+ffXP/Cfvv8A4zR/wnujf8++uf8AhP33/wAZrpKKAOb/AOE90b/n31z/AMJ++/8AjNH/AAnujf8APvrn/hP33/xmukooA5v/AIT3Rv8An31z/wAJ++/+M0f8J7o3/Pvrn/hP33/xmukooA5v/hPdG/599c/8J++/+M0f8J7o3/Pvrn/hP33/AMZrpKKAOb/4T3Rv+ffXP/Cfvv8A4zR/wnujf8++uf8AhP33/wAZrpKKAOb/AOE90b/n31z/AMJ++/8AjNO8BQyweBtOS4hlgk2uxjmjaN1BkYjKsARwRwRXRUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFc38R/8Aklniv/sC3n/oh66Sub+I/wDySzxX/wBgW8/9EPQB0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABWN4x0y41rwLr2l2IVrq+024t4QzYBd4mVcntyRR4g8RroT2MMemX2qXV/MYobaxEe/hSzMTI6KFAHUnqR61ieH/iVb+IrnTFt/DutW1tqks0NveTrbmLdEH352TMwGUYA4wT045oA7SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDC8ba4PDXgXWtYLhGs7KSSMk9X2kIPxYgfjVHw8tt4G+F+kQ3KTSpY6fGJBbQtKzuI9zkBfU7jk8e9b+qaRput2f2TWtOtNQttwfybuBZU3DodrAjPNUtc0+7XwnPpnhmysFc25toIZpTbwxIV2jGxGwFGMKABxjIoAv6ZfxarpNnqNurrDdwJPGsgAYKyhgDjPODVqsbwlZ6lpvhPTtP1mK1jurO3S3P2SdpUcIoUNlkQjOM4xx6mtmgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqJbq3e8ktFmjNxGiyPEGG5VYkKxHoSrAH2NF1cxWVnNdXLbIYI2kkbGcKBkn8hXyd4U+J+tr+0DP4k1CzvY9P1OQW1xA0TfuLYnbESO23aDnvh/WgD62ooByMiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKw/FnjHRvBWkf2hr1yYkd/LhijUvLO56Iijkn9PXFcinxB+IF6gn0r4TXkls4yjXmswWshHvGwJH0oA9Korzb/hNvid/0SP8A8uW2/wDiaP8AhNvid/0SP/y5bb/4mgD0mubsf+Sp67/2BdN/9H31c1/wm3xO/wCiR/8Aly23/wATWbBr/wATofFV9rP/AAqnd9rsra08n/hIrb5PJed927HOfPxjHG3vngA9borzb/hNvid/0SP/AMuW2/8AiaP+E2+J3/RI/wDy5bb/AOJoA9Jorzb/AITb4nf9Ej/8uW2/+Jo/4Tb4nf8ARI//AC5bb/4mgD0mivNv+E2+J3/RI/8Ay5bb/wCJo/4Tb4nf9Ej/APLltv8A4mgD0mivNv8AhNvid/0SP/y5bb/4mj/hNvid/wBEj/8ALltv/iaAPSaK82/4Tb4nf9Ej/wDLltv/AImj/hNvid/0SP8A8uW2/wDiaAPSaK82/wCE2+J3/RI//Lltv/iaP+E2+J3/AESP/wAuW2/+JoA9Jorzb/hNvid/0SP/AMuW2/8AiaP+E2+J3/RI/wDy5bb/AOJoA9Jorzb/AITb4nf9Ej/8uW2/+Jo/4Tb4nf8ARI//AC5bb/4mgD0mivNv+E2+J3/RI/8Ay5bb/wCJo/4Tb4nf9Ej/APLltv8A4mgD0mivNv8AhNvid/0SP/y5bb/4mj/hNvid/wBEj/8ALltv/iaAPSaK82/4Tb4nf9Ej/wDLltv/AImj/hNvid/0SP8A8uW2/wDiaAPSaK82/wCE2+J3/RI//Lltv/iaP+E2+J3/AESP/wAuW2/+JoA9Jorzb/hNvid/0SP/AMuW2/8AiaP+E2+J3/RI/wDy5bb/AOJoA9Jorzb/AITb4nf9Ej/8uW2/+Jo/4Tb4nf8ARI//AC5bb/4mgD0mivNv+E2+J3/RI/8Ay5bb/wCJo/4Tb4nf9Ej/APLltv8A4mgD0mivNv8AhNvid/0SP/y5bb/4mj/hNvid/wBEj/8ALltv/iaAPSaK82/4Tb4nf9Ej/wDLltv/AImj/hNvid/0SP8A8uW2/wDiaAPSaK82/wCE2+J3/RI//Lltv/iaP+E2+J3/AESP/wAuW2/+JoA9Jorzb/hNvid/0SP/AMuW2/8AiaP+E2+J3/RI/wDy5bb/AOJoA9Jorzb/AITb4nf9Ej/8uW2/+Jo/4Tb4nf8ARI//AC5bb/4mgD0mivNv+E2+J3/RI/8Ay5bb/wCJo/4Tb4nf9Ej/APLltv8A4mgD0mivNv8AhNvid/0SP/y5bb/4mj/hNvid/wBEj/8ALltv/iaAPSaK82/4Tb4nf9Ej/wDLltv/AImj/hNvid/0SP8A8uW2/wDiaAPSaK82/wCE2+J3/RI//Lltv/iaP+E2+J3/AESP/wAuW2/+JoA9Jorzb/hNvid/0SP/AMuW2/8AiaP+E2+J3/RI/wDy5bb/AOJoA9Jorzb/AITb4nf9Ej/8uW2/+Jo/4Tb4nf8ARI//AC5bb/4mgD0mivNv+E2+J3/RI/8Ay5bb/wCJo/4Tb4nf9Ej/APLltv8A4mgD0mivNv8AhNvid/0SP/y5bb/4mj/hNvid/wBEj/8ALltv/iaAPSaK82/4Tb4nf9Ej/wDLltv/AImj/hNvid/0SP8A8uW2/wDiaAPSaK82/wCE2+J3/RI//Lltv/iaP+E2+J3/AESP/wAuW2/+JoA9JorzOX4qa9oO248e/D/UNC03OJL+2vI7+OH/AGnEYyq+/NeiWF/aarp8F9p1xHc2twgkimibKup6EGgCxRRRQAUUUUAFFFFABRRRQB5hp9rH4p/aG16bVFE8XhK0tYrCFxlY5bhDI0oH97Axn6egr0+vNvBP/Jdvif8A9wn/ANJmr0mgAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAGSxRzwvDPGskUilXR1yrA8EEHqK82+FUX9g+LfG/gy2Zv7N0a9guLKMnPkpcxmQxj/ZBBx9TXplebeCf+S7fE/wD7hP8A6TNQB6TRRRQAUUUUAFFFFABRRRQB5t4J/wCS7fE//uE/+kzV6TXm3gn/AJLt8T/+4T/6TNXpNABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXkH7Sut6roPw20+60PU7zTbh9WjjaWzuGhdlMMxKkqQcZAOPYV6/XiX7Vf/JLNN/7DUX/AKInoA4/xXo/xE+GXhGw8Z2nxJ1HVo3aHzLS9MjKN4yBtd3DDseh717XbfE7w9DYeGv7dvl06/8AENlDdW9u0bsvzqpILhSqgFsZYivOtF/Z9m1y20u68aeOtX17T1ijmj0+TeqplQdu5pHwMHHygHHQiqXxs0Sz1P4yfDzRZo9ljNi3eKP5R5XmKCgx0BXj6UAexaX4/wDC2s+HrzXdP1q3fS7GZoLi7kzHGjqFJGXAzwy4IyDniqHh/wCLXgbxRq40vQ/EMFxesSEhaOSIyEdlLqA3TtmvK/2j9GtvDfgXQrPw/p9vpejPqZkvI7O2VUMnlgIzKMBjtVuvXaKq3WgWfi+88Nm7+NelajNb3MTaZbWui28c0bll2rticMnQcMMDHTigDZ8ZfHuHR/jDp+i2OqQR+HrRzFrExs5GkjmV5Fkj5XJA2pyoPU4Pp6ZN8TfCFvJoqT6wsZ1yITaeXglAmQ9GJ24Qc/xYrxT4qad4d0v9pzww+p2Om2ulXVsk9+ZoEWGZ2ln3PLkbWJ+XJb2zVn4u6Xo2ufFT4baZYi3OiXarCi2RURNAZFG1NvG0rxxxg0Aex2vxL8HXnhu61+DXrb+yrW5NrLdOGRfNAB2DcAWOGBG3Oe1R+Gfin4L8YakdP8O69Dd3mCRA0ckTOAMnaHUbsDnjNcN8YLnw34H8O6J4e0zwjpNw2rajvtrSRPItFlVVTzJQmA3DqOTz1PSvPb/R9Q8P/HzwOmp23hbTr6W5jL2vhmF4kRCwA8wHuwLc9xntigD1SDTNAH7S1zqC+K7ttbNgFbQzbyeWqeWoz5mNu3GG2f3jnPaugf4veBIotVkm8QRRLpE4t7zzIJVKSEuAqgrlz+7f7melef2v/J6F7/2Ch/6JSsX4L+E9C8SfEn4iza/plvqX2TUdsMV1GJI13yz7jsPG75Bg9Rk460Ae7eGfFuheMdLOo+GtRiv7YPsZkBUo3XDKwDKfqKwNS+Mvw/0nWG0u+8TWqXaPsdUSSREbuC6qVH4nivFfhdHd6WnxisfDYeKS2glWzjiJLIUM6pt77gOnvisj4cRW+qfC+60mf4q6V4atLgyx3uk3mlWzO4b+ISOyu+VxgjlegxgUAfU9/wCINI0zQTrV/qNtBpgjEn2tpB5ZU/dIPfORjHXPFfPX7QHxK8I+N/hvaWvhfWY764g1eKSSLypI2C+TMNwDqCRkgZHqKy/ibpMfh/4WfDnS31mbWfDH2yWWe+SAxeZGzK0eFySMI8uOe3bpT/jv/wAKuHgvTB4HXRjqf2hdp0rZkQ7W3ebt752/e+b9aAPpbw9/yLOl/wDXnF/6AK8u/aP1bV9K8JaJ/YWrXulz3GqLC01ncPExUxvwSpBIzg49q9R8Pf8AIs6X/wBecX/oArxr9q7/AJJ/o/8A2FB/6KegDoPgD4s1HXfCN/o3iO5nuNb0G8e2uWuZDJKykkqWY8kgh15/uCvHPjH8RfE17441e68Oa/qenaRplymmRrZXckKSyKrGRvlYAncCM+m2ur+Imq3Pwc+NGo+IrBP9C8TaVNtUfdF0q8HH++EJPpI1ch8RvCr+FfgD4PjulIvtQvZL+7LfeLyR5AbPOQu0H3BoA+qtf8SaP4W003/iHUYNPtc7RJM2Nx9AOpPsOaw/DXxX8EeL9RFh4f8AEEFzdtnZA8ckLvgZO0SKu7jnjNeU/HM2X/C7/BQ8Yg/8Ir5Pzl8+X5nmNvzjt/qc+1YXxiXwUda8KD4UjRzr/wBtXZ/Y2zb1XZv8v5c7sdeetAH0H4q8ceG/BNtFP4o1aGwWYkRKwZ3fHXCKCxAyMnHGa8J1/wAVaJ4w/ai8D6n4b1CO/s/skUZkQMu1hJOSpVgCDgg4I7in+LH0OT9rN1+I5gGjR2UYsft2PIP7oEb88bd5l68ZxVC+Pg3/AIak8Lf8ICtkLTKfaTp+37OZfn+5t+X7u3O3j8c0Ae9+KviN4S8FSRx+JtbgsppBuWHa0khHrsQFgPfGKy/EvifRfFvwY8Vaj4c1GG/tf7HvELxE5VvIbhgcFTyOCBXh9te38P7RHjA3/ja28HagbiRbe9vdPhuFeHd8iBpSBH+72HryK6vQPC9jo/gr4oanpnje28UG+0m5+2GzslgiWbyZW3Ao5Qn5jwuBzQB137Of/JEdK/67XH/o5q9Rry79nP8A5IjpX/Xa4/8ARzV6jQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAV5t4J/wCS7fE//uE/+kzV6TXm3gn/AJLt8T/+4T/6TNQB6TRRRQAUUUUAFFFFABRRRQB5t4J/5Lt8T/8AuE/+kzV6TXmfh2VdI/aH8Y2d6fLk16ysbyy3cCVYYzG4B7kE5x6A16ZQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVieK/B2heN9Kj03xPY/brSKYTpH5zx4cKyg5RgejNxnHNbdFAEdvbx2trFb267IoUCIuScKBgDJ9qxtX8F6BrviHTdc1Ww8/UdLbdZz+dIvlHOfuqwU8+oNbtFAFPVdI0/XdMl07WLOG9s5hiSGdAyt3HB7g857Vy+g/CDwH4a1dNU0bw7BDeRtujlklkl8s+qh2IU+4ArtKKAOc8WfD/wv44EH/CU6RHfNb58p/MeN1B6jchBx7ZxUTfDjwo93ody2lfvvD6LHprC4lH2dVIIGN2G6D72a6iigDG8TeEdB8ZaYNP8AE2mxX9srb1VyVZG9VZSGU/QisSw+EPgXTLnTLjT/AA/FbzaVKZ7SRJ5QVckHcx3fOflH3s9K7SigDCTwXoCeNH8WLYY1uSLyWuvOk5TAXGzdt6AdqPD3grw/4V1DVL7QbD7LcatKJr1/OkfzXBYg4ZiF5dumOv0rdooAwPD/AIG8O+FtV1LUtC077Ld6o/mXknnyP5rbi2cMxA5Y9AOtYl/8FPh3qeqtqN34XtjcO25vLkkjRj6lFYL+ld1RQBk6h4W0LVfDq6Df6VazaUqKiWhjARAvC7QPu47EYxXMD4IfDsaK2lDw1ELR51uGAuZg7Oqsqkyb95ADtxnHPSu9ooAjt7eO1tYre3XZFCgRFyThQMAZPtWN4s8FeH/HGnw2Piiw+3W8EvnRp50ke18EZyjA9Ca3aKAMLxT4K8PeNba2g8T6al/Fay+bCrSOm1sY/hIyPY8H0pnizwN4d8cWdva+KNO+3Q2zmSJPOki2sRjPyMM8etdBRQBl+IPDOjeKtMOn+ItOg1C13bgky52t0yp6qeTyCDWL4Z+FngrwffG98PaBb2112nd3mdP91pGYr+GK66igDnfFfgDwv43SJfFGjw35h4jkLNHIo9A6ENj2ziqVr8KvBVjrGl6pZaDFb3mkxiOzkimkURqGZuVDbWOXY5YEnPJrr6KAOW8U/DXwh40uEuPEuhwXlwi7ROHeKTHYFkIJHsTVjTPAfhjRvDN54e0vSIbXTL6J4rmGNmBmV1KtufO4nacZzkdq6GigDL8OeGtJ8JaHFpHh+0+yWMLMyReY8mCxJPLEnqT3rUoooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK828E/8l2+J/8A3Cf/AEmavSa8z+Gkq6v8SviJ4isz5mn3l7aWcEw+7I1vCUcqe4yRzQB6ZRRRQAUUUUAFFFFABRRRQBy/jfwHYeNbW0aW4uNP1PT5POsNStWxLbP7eqnAyO+O1c6lp8arJBBBqXgvUkQYFzew3MUr+5WP5QfpXpVFAHm3/F7/APqn/wD5O0f8Xv8A+qf/APk7XpNFAHm3/F7/APqn/wD5O0E/G4Yyfh+M8D/j95r0mvmn46fFy70n4o6PYaBNmPw7MtzcqrfLNMwwUPsIyV/4G3pQB6b/AMXv/wCqf/8Ak7R/xe//AKp//wCTtd3omsWniDQbLV9NfzLW9hWaJvYjOD7joavUAebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7QD8bj0Pw/Pbj7bXT+PfFtv4H8Eajr1ztZraLEEbH/WynhF/EkZ9sntXj37NPxHuNYk1Tw1rl00140r6hbSSHl97ZlX/AL6O7/gTelAHdf8AF7/+qf8A/k7R/wAXv/6p/wD+Ttek0UAebf8AF7/+qf8A/k7R/wAXv/6p/wD+Ttek0UAebf8AF7/+qf8A/k7R/wAXv/6p/wD+Ttek0UAebf8AF7/+qf8A/k7R/wAXv/6p/wD+Ttek0UAebf8AF7/+qf8A/k7R/wAXv/6p/wD+Ttek1zvj3xbb+B/BGo69c7Wa2ixBGx/1sp4RfxJGfbJ7UAcwD8bj0Pw/Pbj7bR/xe/8A6p//AOTtcL+zT8R7jWJNU8Na5dNNeNK+oW0kh5fe2ZV/76O7/gTelfQdAHm3/F7/APqn/wD5O0f8Xv8A+qf/APk7XpNFAHm3/F7/APqn/wD5O0f8Xv8A+qf/APk7XpNFAHm3/F7/APqn/wD5O0f8Xv8A+qf/APk7XpNFAHm3/F7/APqn/wD5O0f8Xv8A+qf/APk7XpNFAHm3/F7/APqn/wD5O0f8Xv8A+qf/APk7XpNc7498W2/gfwRqOvXO1mtosQRsf9bKeEX8SRn2ye1AHMA/G49D8Pz24+20f8Xv/wCqf/8Ak7XC/s0/Ee41iTVPDWuXTTXjSvqFtJIeX3tmVf8Avo7v+BN6V9B0Aebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7R/xe/8A6p//AOTtek0UAebf8Xv/AOqf/wDk7VTVtV+MWh6Rdapqk/w9t7O0iMs0rfbvlUD9fp3r1SvEv2lZ/El54Si0fQdKvJ9P2teapdxITGkcfIUn6gsfTavrQB0MMvxrnhSaF/h9JHIoZHU3pDAjIIp//F7/APqn/wD5O0nwMm8SQ/D+PR/F+lXlhd6W3kwPcxlfNh6pg/7PK/QCvSqAPNv+L3/9U/8A/J2j/i9//VP/APydr0migDzb/i9//VP/APydo/4vf/1T/wD8na9JooA82/4vf/1T/wD8naP+L3/9U/8A/J2vSaKAPNv+L3/9U/8A/J2oobr4z3Es8UE3w7kkt3Ecyq16TGxUMAw7HawP0Iru/EmuQ+G/DN/rFxG8qWcLSeVGMtI38Kj3JwPxr5q+Bfj3W4PitqMfiGK6MHiKYm4domCw3P3kPP3QQduPQr2FAHr/APxe/wD6p/8A+TtH/F7/APqn/wD5O16TRQB5t/xe/wD6p/8A+TtH/F7/APqn/wD5O16TRQB5t/xe/wD6p/8A+TtH/F7/APqn/wD5O16TRQB5hdeF/ij4rhOn+KvEWiaPpko23I8PRSmaZD1QPL9zPqP1rvfD+gad4X0G10bRbcW9lapsjQHJ9SSe5JJJPqa0qKACiiigAooooAKKKKACiiigAooooAKKKKACuK8V+H9Gk8TeFJJNIsGe51mXz2a2QmX/AEG7b5jjn5gDz3ANdrWLrmm3N9rHhu4t1DR6fqT3E5LAbUNpcRAj1+aVB+NAGpa2ltY2y29lbxW8KZ2xQoEVe/AHFTUUUAFFFFABRRRQAUUUUAFFFFAFe90+z1KAQ6jaQXcQbcI54g6g+uCOvJrlfh9oekwaRPdQaZZx3EesaoiTJboHVRfTqAGAyAFGPpxXZVi+FNNudK0ee3vVCyPqV/cKAwPyS3csqH8VdT7UAbVFFFABRRRQAUUUUAFFFFABVe90+z1KAQ6jaQXcQbcI54g6g+uCOvJqxRQBxvw+0PSYNInuoNMs47iPWNURJkt0Dqovp1ADAZACjH04rsqxfCmm3OlaPPb3qhZH1K/uFAYH5JbuWVD+Kup9q2qACiiigAooooAKKKKACiiigAqve6fZ6lAIdRtILuINuEc8QdQfXBHXk1YooA434faHpMGkT3UGmWcdxHrGqIkyW6B1UX06gBgMgBRj6cV2VYvhTTbnStHnt71Qsj6lf3CgMD8kt3LKh/FXU+1bVABRRRQAUUUUAFFFFABXN/Ef/klniv8A7At5/wCiHrpKzvEOkLr/AIZ1TR5JTCuo2ctq0qrkoJEK7sd8ZzQBo0UUUAFFFFABRRRQAUUUUAFc34X/AORi8Z/9hqP/ANN9nXSVlaRpMunapr11JIjrqd+t1GFzlFFtBDg++YSfoRQBq0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAcr4m8U6tpHijRNE0bRrTUJdWSdhJcag1usPlKGYsBE5IO4DI7kD3rQ8P6prOoTajDr2ixaY9nMscbwXTTx3IMavvRmjQ4G7b06g+lee+I9V8Kar8XtQh8S+JIdLg0XSUt4imsNZSedM7NJgo6lsJHHleRkjI6V0sXiuy0L4a6RqXh/Sbu70oQww2290i2w70iR2yc8hgwwCSOuKAO3ooooAKKKKACiiigAooooAKiuZJIrSaSFY2kRGZFkfYpIHALYOB74OPSpa5H4p66nh74Y63d/aI4JpLZra3Z3C/vZBsXGfQtn6AntQBnaJ458Wa34a0jXovB1mLHUpIQI49WkeeKOSQJ5hT7OFIAO8/N93mu/rzbwS3gfTfEdpp3hPWJdbv00kxbYNTa9htoYygOCzsItzFAFUgfKOABmuk0jxJql14oOjavoa6ezWP22OSK8E+1d4TZKAoCPknGCyna2GOKAOlooooAKKKKACiiigAooooAK4o/Enedaa18Ja/dQ6JPJBeTRfZAoZFDnaGnDN8pB4GeRxniuzkkSGJ5JWCoilmY9AB1NeUeBbVodF0XxRqfii+so9c1WW+/soJGIrl7lnESDagkPDRscsyjbyABkAHqVjdrf6fbXaRyRLcRLKEkADKGAODgkZ59anrnLrxlDZa7Bp93pGqww3F2LKK/eFBA8xUsFHz7yCAfm2beOtdHQAUUUUAFFFFABRRRQAUUUUAUtav5NL0K+1CGKOZ7W3eYRyy+WrbVJwWwdo464Ncto/i3xZqWn6FqUvhKzjsdXMLN5OqySzWsci7t7obdRwOo3dSBTPjDq0Gm/DTULaa8itH1Qpp6SSyBABM4Rzk9gjMxPYCovBU/guLxZd2fg/VZtXnbT4zNKNSe+hto43IRBI7sVLF2O0HGE6DjIB31Fc94e8Ww+I9a1WztLdlt7AQmK5L8XIk3/ADKMcL8hwc/MDkcYz0NABRRRQAUUUUAFFFFAEN7I0NhcSJLHCyRMwklQsqEDqQCCQO4BH1rzzw54g8ea34b0HVWu/Dn2nU1gupNLWxkSVbV5FDyK7XPO1HDfc6kDqRnd+J9xeQfDXWYtLtru5vLu3a1hSzt3mcGT5C21ATgAk59vXFZvg+Lw1p/iSK08JeEbqw32BF3qUmkTWEeEYBUPmRrvdixPHOAck4xQB31FcR4J8V6lrN8LbXr21hvXtTP/AGZ/YtzZSp8wBYSSyESqM4JRcZI5HQ9vQAUUUUAFFFFABSNuCnYAWxwCcAn60tYPjjX4/C/gXWNYklWJrW0kaIs2N0m07FHuWwKAOb0nx34u1nwumvWXg6wltnmaJYY9ZkaZwsxiLqv2bBXILfeHyjNehV5P8PV8EaTqHhqw0TXH1jWf7Ne3aK21VryGD5EeWQoXZYssgUbcffxjHI7XRvGVjr2tz2emy2bxQPJFua7AmkZDhikOCSgII3EjOMgEYJAOjooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5jx3pF34g0eDSbTW7PSRdzoCbm0M7TMhEqqg8xMH92SeuRnpjNdPXy38e/HWty/FLTLfw9HdLH4elDQyJE2Jbn7zY4+YBRtx7NQB9P2i3KWcS30sU1yFAlkhiMaM3chSzFR7Fj9alrK8Ma7H4m8L6frEMTwC7hV2hkBDRN0ZDnuCCPwrVoAKKKKACiiigAooooAKKKKAEbcVOwgNjgkZAP0rlfCOk6vZ3U91feItO1eGQypO1rp5hklnDhdzyGZ/ubGQIoUDPsBTviR4ol8H+AdS1W0iea8WPy7SNELEytwpx6D7x9ga8W/Zl8X6nDqWoeGdZjujBdu91azyo21Zgf3qEkdTgn6q3c0AfSVFFFABRRRQAUUUUAFFFFAEVza297ayW15BHcQSqUkilQMrqeoIPBFY9l4G8J6bexXmneF9FtLqE7o54NPiR0PqGC5FbtRXNzFZ2k1zcNtihRpHbGcKBknH0FAHEX2haxqXxHtbv7VYJ/Z0qTh0vpjKts25fLNqVMYLYceaGBwMY4rvK+SfDXxQ1tf2gpvE19Z3qadqDi1ngMLfubUnbGSMcbSob3Ib1NfWwORkUAFFFFABRRRQAUUUUAFFFFABUF7Zw6hYXFldBmguImikCOyEqwwcMpBBweoII7VPXK/EnxVJ4O8BajqtpC896E8q0jRCxaVuFOAOg5Y+woAo+FvAWmaR4uvtf03UpL23eNbWCCS6nnNs0e5HG95mDHquCoK4IBGTnuK+bv2ZfGGow6hqHhjWo7oxXbvdWs0qNgTA/vUJPc4z9Vbua+kaACiiigAooooAKKKKACmyKHjZSxUEEEqcEfjTq5b4j2/iK+8B6hYeDoUk1O8TyFZ5RGIkbh2ye+Mge5B7UAZXw7Gia+W17Tde1PXn09p9Mhl1GSNjAodd23Yi7t4SNt77mIxz1rvq+e/2efB/jXwhrV81/awnQ7x5racrcqTHPBI0e4L1I3K68dQQe1fQlABRRRQAUUUUAFFFFABXBaN4EittbtRHrNrcWWh6hNdQ28VmFuI5ZUc7JZg53KFnJACKT8uScc9V4j1uLw54bv9YuI3lSzhaTy4wS0h7KMdycD8a+a/gZ4+1uH4r6lH4giujB4imJnZomCw3P3k/3QQdv4r2FAH1PRRRQAUUUUAZHivxLZ+D/AAve69qcVxLa2SB5Eto98hBYLwCQOpHUgAc1RvPHWmWWs+HNMlt74zeIlZrRlg+WMKgc+Zk5U4PTB98V0tFAGDo/jDT9b8Ua3oNpDdpdaK0a3DyxbY3LrkbDnnp3A9sjmt6iigAooooAKKKKACiiigAooooAKKKKACiiigArmvFnGseEj6a1/wC2lyP610tY+vaZcajfaFLb7dtjqIuZdxx8nkypx6nLigDYooooAKKKKACiiigAorz34neIPEGlan4c03wzex2c2q3Dws8kauM7o1XO5WwMuc4Gaqf2H8Xv+hp0n/v0v/xiuaWItJxUW7dv+HPZpZS50IV51oQU72Um76NrpF9Uem0V5l/Yfxe/6GnSf+/S/wDxij+w/i9/0NOk/wDfpf8A4xR7d/yS/D/Mr+yYf9BVL75f/Inptc34F/5At/8A9hrUv/SyWuW/sP4vf9DTpP8A36X/AOMVV07wp8VdPgljs/EWlQJJcSzspQNud3Ls3+pPVmJx2z0HSj27/kl+H+Yf2TD/AKCqX3y/+RPV6K8y/sP4vf8AQ06T/wB+l/8AjFH9h/F7/oadJ/79L/8AGKPbv+SX4f5h/ZMP+gql98v/AJE9NorzL+w/i9/0NOk/9+l/+MUf2H8Xv+hp0n/v0v8A8Yo9u/5Jfh/mH9kw/wCgql98v/kT02iuH+E3iTVPE/hK4vNbuBcXEV68IkEaplQiMOFAHVjXcVtTmqkFNdTzsZhZ4OvLD1LXi7abBRRRVnKFFFFAHN2f/JU9Z/7Ath/6PvK6Sse30y4i8cajqrbfs1xp1rbJz82+OS4ZuPTEq/rWxQAUUUUAFFFFABRXmnjjXfFf/CyNM8NeFNSgsTd2XnZmiVlLAyE5JRiOI+MDrTf7D+L3/Q06T/36X/4xXM8R7zSi3b+u57ccnfsoVKleEOZXSbd7arpF9j02ivMv7D+L3/Q06T/36X/4xR/Yfxe/6GnSf+/S/wDxij27/kl+H+Yf2TD/AKCqX3y/+RPTaK8y/sP4vf8AQ06T/wB+l/8AjFH9h/F7/oadJ/79L/8AGKPbv+SX4f5h/ZMP+gql98v/AJE6nwJ/yAb3/sNan/6XTV0leUad4U+KunW8kVn4i0qBHuJZ2UoGy8kjO7f6k/eZicds9B0q1/Yfxe/6GnSf+/S//GKPbv8Akl+H+Yf2TD/oKpffL/5E9NorzL+w/i9/0NOk/wDfpf8A4xR/Yfxe/wChp0n/AL9L/wDGKPbv+SX4f5h/ZMP+gql98v8A5E9NorzL+w/i9/0NOk/9+l/+MVq/CbxJqnifwlcXmt3AuLiK9eESCNUyoRGHCgDqxpxrqU1Bxav3/wCHIr5VKlQliIVYTUWk+Vu6ve28V2O4oooroPHCiiigDm/An/IBvf8AsNan/wCl01dJVDRtJj0ayltoZGkWW7uLol8ZDTTPKR9AXIH0q/QAUUUUAFFFFABRRRQAVzfhn/kZvGP/AGFov/SG1rpKx9F0y4sNZ8Q3U+3y9Qv0uINpydgtYIjn0O6NvwxQBsUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVgW/iC9uvGuoaNFYW62WnQxST3j3bCTMisVCxeXgj5eSXH0Nb9cHJZz6j4m+IFlZnFxc6bbRREnGGaGYDntyaANC18VazrkAvvC+gQXelsT5V1fagbY3Kg/fiQRvlTzgsUz16EGr0niV4vGGlaDLYlH1CwmvGkaUZhMbRgoQAQf9Z1B7d81B4G1qw1DwRYNbstubK2S3uraT5Xs5EUK0bg/dKkEc/UcVmX8sc/xp8NTQSLJFJol8yOjZVgZLcggjqKANvW/EM9jq9no2k2C3+qXkMtwkc0/kRRxRlQzu+1iOZEACqxOfQZqprfiLXtE8E3+tz6DZG506OWe4tTqbBGhjQuWjkEJLE4ACsid8kYGZfE/h3TPEN5aBtQl03W7QNJZXdnMqXEQPDYU5DIcAFSCDj15rlL3W9S1X4R/ECz1ia3vLjSbS9sjf2qbY7sC137tuSFYb9rAHAZT9KAPSreX7RaxTbdvmIGxnOMjNSVX07/AJBdr/1xT/0EVYoAKKKKAPMvih/yPXgD/sJH/wBGwV6bXmXxQ/5HrwB/2Ej/AOjYK9MZQ6FW6MMHBxXNS/i1PVfke3j/APcMJ6T/APS2eSalrvie3+LWmaY/i3SV22skMxTSZxaxzylTFHIv2rBlYRuUywIAPB3Cug0vxHLqfxQ02xE9/ti0K6a6SbT7myhlmE1sPMSOYDPV8YLbQ2M885WtjTNLmvfCOjNYJZLEkt3p/wDwid9qjZkyQ8ksMgBLFSQT83y9eKn8HT38/juyjuIGurWz0WaCK+fQdQ08w/vYMRFrmRhJuC7s/e/d9eTnpPEOr1jxhYaZdy6daRzarq6AY06yTfICRkbz92MEEHc5Ax+FY+geK77QtMhsPiXJ9j1NM7tRKYs7gE5G2VVCqQCFKttOVJGRzWvc+HNUnupZYvGmuWySOWWGKGxKRgnIVd1sWwOgySfUmua8CW3iHxP4KsNYv/G+tR3Fz5m9YLawCDbIyjANsT0Ud6AO11aLV54Y/wCwb+xs5N2Xa8snuVYY6ALLHg++TXHT654jNr42sdQvbGddJ0vdFe6faSWrJcPFI5TmaTlVETZBB+cV0mrt4ht7C0sPD6JdXUieXLql+yBYMADzGjQLvc8kKoVc55UYrN1HQYPDnwt16zglkuJHsLua5upiDJcTNGxeRscZJ7DgAADgCgDoNCkebw7p0krs8j2sTM7HJYlBkk9zV+uf8GaFpGi+GrJtH0uy083NtC85tbdIvNbYOW2gZPJ5PrXQUAeZfAf/AJEW8/7CT/8AoqKvTa8y+A//ACIt5/2En/8ARUVem1zYX+BH0Pbz/wD5Glf1Ciiiuk8Q5EeOJYIPEmoahp0UOk6HLJB5sV0ZJ53QKceWUCqDvAB3nnrgc1qaXf8AiGe8VdX0K1srV1JWSDUfPdD6OhjUD/gLNz+dYGgW2m3mneM7XXVgbT7jW54p1uGCoytHEuCT0ySAPfGKi006l4O8Y6N4fj1l9Z0fVVmEEV4Q91YiOMuG8wcyRcbcsMgsvzHNAF3RvFfiPxBc37aboGlixstTuLBpbjV5ElbyZCjPsFuw5xkDd7Z70+58V63N4w1XQ9B0KxvP7Lgt5ppbrU2t2fzt+AqiFwSPLPVh1FYXw80e+uW1+7h8R6nZwr4m1EmygjtjE2Llsgl4Wfnvhh7Yp9vba3c/GLxeuhanZ6ePsOmiZrmxa4ZuJ8bMSoFI56hgcjjjkA1F8fTXOnaJqVjpUb2OoXy6fcie7Mc9pOZTEy7AjK+1lOfnX2612lcDruhW3hvw14a02zeSVY/EFo7zSkF5pHmLu7YAGWZieABzxgV31ABRRRQB5lrn/Jxvhz/sGv8A+g3Fd14lvbzTfCmrX2lw/aL61sppraHaW8yRUJVcDk5IAxXC65/ycb4c/wCwa/8A6DcV6bXNQ3n/AIv0R7ebfBhf+vS/9KkeV61fW3hj4fW3i7TvF1xPfSrCy3F9ftPbXrOVDL5BcRqOSf3ewrjrgGtfwBrlxrXirxL5viLT9eghW0EU2mZW2QlZNwVfNkAPAzhueOKg07Tn1rxLq2peGdI8MaPJY30lo1/c6X9pup5ExvY7HjKDJ4yzEgZ4zWj4SkuP+E48TwaskX9qpFZtNLaufIljIlEZVCNyN8r7lLN/CQea6TxDF8VX/i288Qtp+g6k1ydMu47uaPTNIOYl5ZIZ5JL2NZMqQSqDJGDgZFOfxDqWoXHge6/tqK6jv9aljk+xWstkrIttNmKWJ5HJZZEOQT1A4yMl15qq2niDUNR8OXur2LaiyG8iuvB+oXSNIiCMSRlVTadqqOSynaDjrnN26db6l4FstMOqSGPX5prifU9PntZJ5Zbe4kd8SxpnLFj8owOBQB1l7e6pr3ji/wBC0nWJdIg0qygnmlggikkllmaTYp8xWGxViycAElhyMVwOsfEC61nSCbbV0g1az8M67/aNrYXRUwXMPlIkhQHKHKuyE8gE4NeialoutWXiy417wwmnzyX9pHa3dvfTPCuYmcxyqyo5JHmMCuBkY5Fef+NNC/4RvQbbS2n+0yReEfELzT7dvmyuIHkbHbLsxx70AenW1rd6r4S01YtXvdPne3hka6thE8jfIMg+ajrznJOM+9eYa/40lstI8TaU3jRrm/ttZsbWwEtxBDeOomg8/asKoWXLSKfl6I4PQ16BM2vN4H0m18LxQrd3VtFE17O422SmMZl2dZGHZehOMkDNYfj7RLXw58Gf7KsN5ht7uwG+Q5eRjfQlnY92ZiWJ9SaAOg8E3dxd2+tm6nlmMWtXcUZkctsRZMBRnoB2HauY+A//ACIt5/2En/8ARUVdF4B/49tf/wCw9e/+jK534D/8iLef9hJ//RUVc1T+PD0f6Ht4T/kV4n1p/wDtx6bRRRXSeIeWWPivWbD4VeGNZ1TXpXl12e2W81K7t4dmnpJGWLBY0RQu5QoL5wZASSBiurvE1TQfB+uXw8Q3GqtHYST2k1zBAHiZY2bOY0VGB+UgFex5OeMfwRfW9l8E/DH2/Trq/tJdMhjmjt7U3OFMf8Ua5Zh2wFP0rMsdHkg03xhD4X03UrTw5caQwtLG5t5Is3ZWXf5ELgOikFMrgAseB1oA6nwbZarPo+k6xqXijVL83VnHNJazQ2ixFnjBP+rgV+CePm+ua5GDWvE//CAa94vHie4abS7nUGSwntrf7M8dvLIFjysYkBKoBnf19a1Ph5beFLC10eGx8Ky6brYskimuW8NT2pDiMeYGnaFV5IPJbk+pIqPwH4GsptKubjxBY3xn/ti9nW1vLmcQEfaXaNxbs3l9MMG289fegDY/tHUk+I+iRjUbr+z9X025uX06aKLbbvF9nC7WCB8/vXyGZuTxgDFdhXJav/yVzwt/2C9T/wDQ7SutoAKKKKACuN8bnWbC40y80fX763a61OztDYrBbvCyPKBITuiMmfL3nhx04rsq808a6VJ4ft7zVIoppLFF3+bc+NNTt3aQ9EWFAwJJwFUNznAAoAsW2paifE3g+70nxZqGr6NrjTvJHd21sitELd3QrtgRx823qc+tdD441bUtF8Oi50hMO1zFHPceQ0/2WFmw83lry20c4/E8A1598O9FudX0Wygm0ptNjs8W97a23jLVIpbJlGNv2YjCdMhfMxgghiOa63x7pthbaXFfS6tqWnz74rWJ4rjUZlck4VfItp0Z3P8Ae6+uaAMDVPFn2Cwe48L/ABF/4SXV1wYtG8q0n+0Nkfu9kEayR56bmb5e+cV6opJQFhtJHIznFeEarDq1ppF1caXqfiDULyKJmgtP7H8Sxec4HCb2u8Ln1Ne2aXpdvpFn9mtJLuSPcWzd3kty+T/tyszY46ZxQBcooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACsC20C+s/G1/rUOoW5s9QiiSe0e0YyAxqwUrL5gAHzcgoenUVv0UAZV94V8PapfLe6noWmXl2n3bi4s45JF+jEE0ureGNB14wnXNE07UjACIjeWkc3lg4yF3A46Dp6VqUUAYreDPC76amnP4b0hrGNi6WpsIjErHqQm3AJ9ag8S+GZdU8F3fh3QJ7LR4LuCS1kJsTKqQujKwRFdArfMCDyOOhzx0NFAEdvF9ntYoc7vLQLnGM4GKkoooAKKKKAPLPi7eQaf4s8EXl2/l29vevLK+Cdqq8JJwOTwO1dB/wALc8Ef9Bv/AMlJ/wD4iuo1DSdN1ZETVdPtb1YySguYVkCn23A4qj/whvhj/oXNJ/8AAGL/AOJrldOrGcpQa1737HvRxmAq4WlRxMZ3gmvdcUtZN9U+5wt/4m+F2o6zPqsutahBe3KJHNLZXWoWvmKmdgYRFQcbmxx3NT6Z4z+HGk3gurXxHq0kgUrtu73UblMH/YlZlz74zXZ/8Ib4Y/6FzSf/AABi/wDiaP8AhDfDH/QuaT/4Axf/ABNO2I7x+5/5kc2Tfy1f/Ao//ImL/wALc8Ef9Bv/AMlJ/wD4iqWj/ET4daDpUOm6Tqn2e0g3eXH9nuG25YseWUnqT3rp/wDhDfDH/QuaT/4Axf8AxNH/AAhvhj/oXNJ/8AYv/iaLYjvH7n/mHNk38tX/AMCj/wDImL/wtzwR/wBBv/yUn/8AiKgvfih4B1CwuLK81fzLe5iaKVPs043IwwRkJkcHtXQ/8Ib4Y/6FzSf/AABi/wDiaP8AhDfDH/QuaT/4Axf/ABNFsR3j9z/zDmyb+Wr/AOBR/wDkTBt/ip4DtbWK3t9Z2RQoERfss5woGAMlPSpP+FueCP8AoN/+Sk//AMRW1/whvhj/AKFzSf8AwBi/+Jo/4Q3wx/0Lmk/+AMX/AMTRbEd4/c/8w5sm/lq/+BR/+ROL+A//ACIt5/2En/8ARUVem1XsdPstMt/s+m2kFpDkt5dvEsa5PU4AxVitKNN06ag+hx5liljMXUxEVZSd7BRRRWpwHO6P4audN1HWvtd5aXumarcvc/ZGsiHRmCqQzmQq64XpsHXrWhpXhzRNCaRtE0fT9OaX/WGztUi3/XaBmtKigDBm8CeELm9kvLjwrokt1LIZZJ5NOhZ3cnJYsVySTznrmteOytYbye7itoUubhVWaZYwHlC52hm6kDccZ6ZPrU9FAGB4j0C+1290rytQt7aysryK8lha0aSSVo23AK/mAKPXKtW/RRQAUUUUAeTeM9XsdC+PGg6lqs/kWkOmnzJNjNtz56jhQT1I7V03/C3PBH/Qb/8AJSf/AOIrpL/QtJ1WRJNU0uyvXQbVa5t0kKj0BYHFVf8AhDfDH/QuaT/4Axf/ABNcip1oSk4NWbvrc+gljMuxFKlHEQnzQjy+64paNvqn3OIv/FPwt1DUJb59UuLW7mx50+nve2bzYGBvMO0vgeuegq5o/j74a6DBLFpOoLAJn8yZ/s1w7yv03O7KWY44ySa6v/hDfDH/AELmk/8AgDF/8TR/whvhj/oXNJ/8AYv/AImqtiO8fuf+ZlzZN/LV/wDAo/8AyJi/8Lc8Ef8AQb/8lJ//AIiqV98RPh1qV5YXV7qnmzadMZ7Vvs9wPLcoyE4C4Pyswwcjmun/AOEN8Mf9C5pP/gDF/wDE0f8ACG+GP+hc0n/wBi/+JotiO8fuf+Yc2Tfy1f8AwKP/AMiYv/C3PBH/AEG//JSf/wCIqhqvxB+G2t2s0GqX0Vws1tLaMzWc4cRSgCRA4TcoYAZwR0HoK6n/AIQ3wx/0Lmk/+AMX/wATR/whvhj/AKFzSf8AwBi/+JotiO8fuf8AmHNk38tX/wACj/8AImDb/FTwHa2sVvb6zsihQIi/ZZzhQMAZKelMvPif8PtQtjb3+pQ3UDMrGKaxldSVYMpwUxkMAR6EA10P/CG+GP8AoXNJ/wDAGL/4mj/hDfDH/QuaT/4Axf8AxNFsR3j9z/zDmyb+Wr/4FH/5E5qw+JHw80tbhbHVfKFzcPcy/wCjXDbpHOWblTjJ7DiqHwH/AORFvP8AsJP/AOioq7T/AIQ3wx/0Lmk/+AMX/wATWjY6fZaZb/Z9NtILSHJby7eJY1yepwBilGnVdRTm1pfbzKq4zAwwlTD4WM7zcW3Jp/Dfsl3LFFFFdR4Rl+H/AA5pvhfS107RUuIrRMeXFNdyziMAABV8xmKrgfdGB7VqUUUAFFFFAGWPDmm/8JN/b7JcPqIiaFHku5XjjRtu4JEW2Jny0ztUZIyea1KKKACiiigArMfw5pUmvDWZ7QT3648uWaRpBDxjMasSsZx1KgZ71p0UAZl54c0q+1a31Se0Av7cgpcxO0UhAOQrMpBdc/wtlfan61oVh4hsUtNUjleJJUmQw3EkDo6nKsHjZWBB9DWhRQBzf/CB6R/z+eIP/Cj1D/4/XRRoIoljUsQqhQWYsePUnkn3NOooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP/2Q==\n"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(os.path.join(root_dir, \"SyntacticParsing.JPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAHrBRTd8zqL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import ElectraPreTrainedModel, ElectraModel\n",
    "\n",
    "class ElectraForSequenceClassification(ElectraPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(ElectraForSequenceClassification, self).__init__(config)\n",
    "\n",
    "        # Electra 모델\n",
    "        self.electra = ElectraModel(config)\n",
    "\n",
    "        # 분류할 라벨의 개수\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.output_layer = nn.Linear(in_features=self.hidden_size, out_features=self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        # electra_output : (batch_size, max_length, hidden_size)\n",
    "        electra_output = outputs[0]\n",
    "\n",
    "        # cls_vector : (batch_size, hidden_size)\n",
    "        cls_vector = electra_output[:, 0, :]\n",
    "\n",
    "        # outputs : (batch_size, num_labels)\n",
    "        outputs = self.output_layer(cls_vector)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rx2fbXDp8-_5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "label2idx = {\"1\":1, \"0\":0}\n",
    "idx2label = {1:'1', 0:'0'}\n",
    "def read_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as infile:\n",
    "        datas = []\n",
    "        for line in infile:\n",
    "            # 입력 데이터를 \\t을 기준으로 분리\n",
    "            pieces = line.strip().split(\"#%#\")\n",
    "            stack, top, bottom, queue, label = pieces[0], pieces[1], pieces[2], pieces[3], pieces[4]\n",
    "            datas.append((stack, top, bottom, queue, label))\n",
    "    return datas\n",
    "\n",
    "\n",
    "def convert_data2feature(datas, max_length, tokenizer, label2idx):\n",
    "    input_ids_features, attention_mask_features, token_type_ids_features, label_id_features = [], [], [], []\n",
    "\n",
    "    for stack, stack_top, queue_bottom, queue, label in tqdm(datas, desc=\"convert_data2feature\"):\n",
    "        # Electra tokenizer를 사용하여 입력 문장을 word piece 단위로 분리\n",
    "        tokenized_stack = tokenizer.tokenize(stack)\n",
    "        tokenized_stack_top = tokenizer.tokenize(stack_top)\n",
    "        tokenized_queue_bottom = tokenizer.tokenize(queue_bottom)\n",
    "        tokenized_queue = tokenizer.tokenize(queue)\n",
    "\n",
    "\n",
    "        # CLS, SEP 토큰 추가\n",
    "        tokens = [tokenizer.cls_token]\n",
    "        tokens += tokenized_stack\n",
    "        tokens += [tokenizer.sep_token]\n",
    "        tokens += tokenized_stack_top\n",
    "        tokens += [tokenizer.sep_token]\n",
    "        tokens += tokenized_queue_bottom\n",
    "        tokens += [tokenizer.sep_token]\n",
    "        tokens += tokenized_queue\n",
    "        tokens += [tokenizer.sep_token]\n",
    "\n",
    "        # word piece들을 대응하는 index로 치환\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)[:max_length]\n",
    "        # padding을 제외한 실제 데이터 정보를 반영해주기 위한 attention mask\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        # 각 문장을 구분하기 위한 정보를 반영해주기 위한 token type\n",
    "        token_type_ids = [0] * len(input_ids)\n",
    "\n",
    "        # padding 생성\n",
    "        padding = [tokenizer._convert_token_to_id(tokenizer.pad_token)] * (max_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        attention_mask += padding\n",
    "        token_type_ids += padding\n",
    "        assert max_length == len(input_ids) == len(attention_mask) == len(token_type_ids)\n",
    "\n",
    "\n",
    "        label_id = label2idx[label]\n",
    "\n",
    "        # 변환한 데이터를 각 리스트에 저장\n",
    "        input_ids_features.append(input_ids)\n",
    "        attention_mask_features.append(attention_mask)\n",
    "        token_type_ids_features.append(token_type_ids)\n",
    "        label_id_features.append(label_id)\n",
    "\n",
    "    # 변환한 데이터를 Tensor 객체에 담아 반환\n",
    "    input_ids_features = torch.tensor(input_ids_features, dtype=torch.long)\n",
    "    attention_mask_features = torch.tensor(attention_mask_features, dtype=torch.long)\n",
    "    token_type_ids_features = torch.tensor(token_type_ids_features, dtype=torch.long)\n",
    "    label_id_features = torch.tensor(label_id_features, dtype=torch.long)\n",
    "\n",
    "    return input_ids_features, attention_mask_features, token_type_ids_features, label_id_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNKZZzB7AGSo"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, TensorDataset, RandomSampler, SequentialSampler)\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import ElectraPreTrainedModel, ElectraTokenizer, ElectraConfig\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(config):\n",
    "    # Electra tokenizer 객체 생성\n",
    "    electra_tokenizer = ElectraTokenizer.from_pretrained(config['pretrained_model_name_or_path'])\n",
    "\n",
    "    # 학습 및 평가 데이터 읽기\n",
    "    train_datas = read_data(config[\"train_data_path\"])\n",
    "    test_datas = read_data(config[\"test_data_path\"])\n",
    "\n",
    "    # 입력 데이터 전처리\n",
    "    train_input_ids_features, train_attention_mask_features, train_token_type_ids_features, train_label_id_features = \\\n",
    "        convert_data2feature(train_datas, config[\"max_length\"], electra_tokenizer, label2idx)\n",
    "    test_input_ids_features, test_attention_mask_features, test_token_type_ids_features, test_label_id_features = \\\n",
    "        convert_data2feature(test_datas, config[\"max_length\"], electra_tokenizer, label2idx)\n",
    "\n",
    "    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
    "    train_features = TensorDataset(train_input_ids_features, train_attention_mask_features, train_token_type_ids_features, train_label_id_features)\n",
    "    train_dataloader = DataLoader(train_features, sampler=RandomSampler(train_features), batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
    "    test_features = TensorDataset(test_input_ids_features, test_attention_mask_features, test_token_type_ids_features, test_label_id_features)\n",
    "    test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features), batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # 사전 학습된 Electra 모델 파일로부터 가중치 불러옴\n",
    "    electra_config = ElectraConfig.from_pretrained(config['pretrained_model_name_or_path'])\n",
    "    model = ElectraForSequenceClassification.from_pretrained(config['pretrained_model_name_or_path'], config=electra_config).cuda()\n",
    "\n",
    "    # loss를 계산하기 위한 함수\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 모델 학습을 위한 optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "    # 모델의 정확도를 저장하기 위한 변수\n",
    "    max_accuracy = 0\n",
    "    global_step = 0\n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        model.train()\n",
    "\n",
    "        total_loss = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "            input_ids, attention_mask, token_type_ids, label_id = batch\n",
    "\n",
    "            # 역전파 단계를 실행하기 전에 변화도를 0으로 변경\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측 결과\n",
    "            hypothesis = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "            # loss 계산\n",
    "            loss = loss_func(hypothesis, label_id)\n",
    "\n",
    "            # loss 값으로부터 모델 내부 각 매개변수에 대하여 gradient 계산\n",
    "            loss.backward()\n",
    "            # 모델 내부 각 매개변수 가중치 갱신\n",
    "            optimizer.step()\n",
    "\n",
    "            if (global_step + 1) % 10 == 0:\n",
    "                print(\"Current {} Step Loss : {}\".format(global_step+1, loss))\n",
    "            if (global_step+1) % 200 == 0:\n",
    "                electra_config.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
    "                model.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
    "                max_accuracy = evaluate(model, electra_tokenizer, test_dataloader, step, max_accuracy)\n",
    "            global_step += 1\n",
    "def evaluate(model, tokenizer, test_dataloader=None, global_step=0, max_accuracy=0):\n",
    "    if not test_dataloader:\n",
    "        test_datas = read_data(config[\"test_data_path\"])\n",
    "\n",
    "        # 입력 데이터 전처리\n",
    "        test_input_ids_features, test_attention_mask_features, test_token_type_ids_features, test_label_id_features = \\\n",
    "            convert_data2feature(test_datas, config[\"max_length\"], tokenizer, label2idx)\n",
    "\n",
    "        # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
    "        test_features = TensorDataset(test_input_ids_features, test_attention_mask_features,\n",
    "                                      test_token_type_ids_features, test_label_id_features)\n",
    "        test_dataloader = DataLoader(test_features, sampler=SequentialSampler(test_features),\n",
    "                                     batch_size=config[\"batch_size\"])\n",
    "    model.eval()\n",
    "\n",
    "    # 모델의 출력 결과와 실제 정답값을 담을 리스트\n",
    "    total_hypothesis, total_labels = [], []\n",
    "    for idx, batch in enumerate(test_dataloader):\n",
    "        batch = tuple(t.cuda() for t in batch)\n",
    "        input_ids, attention_mask, token_type_ids, label_id = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 모델 예측 결과\n",
    "            hypothesis = model(input_ids, attention_mask, token_type_ids)\n",
    "            # 모델의 출력값에 softmax와 argmax 함수를 적용\n",
    "            hypothesis = torch.argmax(hypothesis, dim=-1)\n",
    "\n",
    "        # Tensor를 리스트로 변경\n",
    "        hypothesis = hypothesis.cpu().detach().numpy().tolist()\n",
    "        label_id = label_id.cpu().detach().numpy().tolist()\n",
    "\n",
    "        total_hypothesis += hypothesis\n",
    "        total_labels += label_id\n",
    "\n",
    "        if idx < 10:\n",
    "            input_ids = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "            input_sequence = tokenizer.convert_tokens_to_string(input_ids[1:input_ids.index(tokenizer.pad_token)] if tokenizer.pad_token in input_ids else input_ids[1:])\n",
    "            stack, top, bottom, queue, _ = [e.strip() for e in input_sequence.split(\"[SEP]\")]\n",
    "            print(\"\\nStack : \", stack)\n",
    "            print(\"Stack Top : \", top)\n",
    "            print(\"Queue Bottom : \", bottom)\n",
    "            print(\"Queue : \", queue)\n",
    "            print(\"Prediction : \", hypothesis[0])\n",
    "            print(\"Label : \", label_id[0], '\\n\\n')\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(total_labels, total_hypothesis)\n",
    "    print(\"Accuracy : {}\".format(accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1YxsOgeAkKF",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0,
     "referenced_widgets": [
      "f50e35cc8a37407d88814d70ba9cb487",
      "7528e4c76be642558b04acfbd2cbb165",
      "1d4427f19e764a2a8bc8e88ed65096cb",
      "bb1e938ba46447e5a8cfe4cd53150664",
      "b0f9eebff31d4a5f97541531879d9711",
      "553d0efd6ecf4b6cad71ebef8784fc87",
      "c5c9283cfe98451980477cae8330e129",
      "8668b8e5b3d745bf90d6561d792d4311",
      "8722a710d71849488569792395df47bf",
      "76642ecf0f5645369e38ad63abe05022",
      "c821f8fe10034a7dac55b362f1bffd39"
     ]
    },
    "outputId": "10b1f5d5-dfe0-4d7e-bdfe-ba326a04a9c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert_data2feature: 100%|██████████| 229639/229639 [02:05<00:00, 1823.27it/s]\n",
      "convert_data2feature: 100%|██████████| 25838/25838 [00:13<00:00, 1899.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/56.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['output_layer.bias', 'output_layer.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current 10 Step Loss : 0.6830276846885681\n",
      "Current 20 Step Loss : 0.6858534812927246\n",
      "Current 30 Step Loss : 0.671859085559845\n",
      "Current 40 Step Loss : 0.6594560146331787\n",
      "Current 50 Step Loss : 0.7104727029800415\n",
      "Current 60 Step Loss : 0.6858646869659424\n",
      "Current 70 Step Loss : 0.6560038924217224\n",
      "Current 80 Step Loss : 0.6595546007156372\n",
      "Current 90 Step Loss : 0.6430388689041138\n",
      "Current 100 Step Loss : 0.6397765278816223\n",
      "Current 110 Step Loss : 0.6679115295410156\n",
      "Current 120 Step Loss : 0.553705096244812\n",
      "Current 130 Step Loss : 0.6264951229095459\n",
      "Current 140 Step Loss : 0.6588068008422852\n",
      "Current 150 Step Loss : 0.618573784828186\n",
      "Current 160 Step Loss : 0.6940891146659851\n",
      "Current 170 Step Loss : 0.5739954710006714\n",
      "Current 180 Step Loss : 0.5435283184051514\n",
      "Current 190 Step Loss : 0.5700815916061401\n",
      "Current 200 Step Loss : 0.6079558730125427\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  1\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  1\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.7062853162009444\n",
      "Current 210 Step Loss : 0.613609790802002\n",
      "Current 220 Step Loss : 0.634958803653717\n",
      "Current 230 Step Loss : 0.425906777381897\n",
      "Current 240 Step Loss : 0.551693320274353\n",
      "Current 250 Step Loss : 0.46248477697372437\n",
      "Current 260 Step Loss : 0.5443786978721619\n",
      "Current 270 Step Loss : 0.5365006923675537\n",
      "Current 280 Step Loss : 0.4027044177055359\n",
      "Current 290 Step Loss : 0.39919111132621765\n",
      "Current 300 Step Loss : 0.4531436860561371\n",
      "Current 310 Step Loss : 0.3523641526699066\n",
      "Current 320 Step Loss : 0.2552711069583893\n",
      "Current 330 Step Loss : 0.2816947102546692\n",
      "Current 340 Step Loss : 0.3164079785346985\n",
      "Current 350 Step Loss : 0.2690376043319702\n",
      "Current 360 Step Loss : 0.2536260187625885\n",
      "Current 370 Step Loss : 0.2983916401863098\n",
      "Current 380 Step Loss : 0.2683798670768738\n",
      "Current 390 Step Loss : 0.2440958172082901\n",
      "Current 400 Step Loss : 0.2165525257587433\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.8940320458239802\n",
      "Current 410 Step Loss : 0.11572855710983276\n",
      "Current 420 Step Loss : 0.31840723752975464\n",
      "Current 430 Step Loss : 0.2125685065984726\n",
      "Current 440 Step Loss : 0.24457192420959473\n",
      "Current 450 Step Loss : 0.38498276472091675\n",
      "Current 460 Step Loss : 0.2289661169052124\n",
      "Current 470 Step Loss : 0.19870609045028687\n",
      "Current 480 Step Loss : 0.42217952013015747\n",
      "Current 490 Step Loss : 0.21098889410495758\n",
      "Current 500 Step Loss : 0.1578785628080368\n",
      "Current 510 Step Loss : 0.1541777402162552\n",
      "Current 520 Step Loss : 0.11312583088874817\n",
      "Current 530 Step Loss : 0.08614423871040344\n",
      "Current 540 Step Loss : 0.25125861167907715\n",
      "Current 550 Step Loss : 0.34319794178009033\n",
      "Current 560 Step Loss : 0.2168634831905365\n",
      "Current 570 Step Loss : 0.20518949627876282\n",
      "Current 580 Step Loss : 0.24939419329166412\n",
      "Current 590 Step Loss : 0.34530124068260193\n",
      "Current 600 Step Loss : 0.30174747109413147\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.915744252651134\n",
      "Current 610 Step Loss : 0.237378790974617\n",
      "Current 620 Step Loss : 0.18914371728897095\n",
      "Current 630 Step Loss : 0.22468635439872742\n",
      "Current 640 Step Loss : 0.20204979181289673\n",
      "Current 650 Step Loss : 0.3119485080242157\n",
      "Current 660 Step Loss : 0.18342843651771545\n",
      "Current 670 Step Loss : 0.25416889786720276\n",
      "Current 680 Step Loss : 0.22913242876529694\n",
      "Current 690 Step Loss : 0.1349172741174698\n",
      "Current 700 Step Loss : 0.10457615554332733\n",
      "Current 710 Step Loss : 0.20681433379650116\n",
      "Current 720 Step Loss : 0.2087995857000351\n",
      "Current 730 Step Loss : 0.24448899924755096\n",
      "Current 740 Step Loss : 0.2152121514081955\n",
      "Current 750 Step Loss : 0.08087443560361862\n",
      "Current 760 Step Loss : 0.16503159701824188\n",
      "Current 770 Step Loss : 0.15475672483444214\n",
      "Current 780 Step Loss : 0.06341856718063354\n",
      "Current 790 Step Loss : 0.2982853651046753\n",
      "Current 800 Step Loss : 0.25625231862068176\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  0\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9275098691849214\n",
      "Current 810 Step Loss : 0.19336538016796112\n",
      "Current 820 Step Loss : 0.14742061495780945\n",
      "Current 830 Step Loss : 0.09250082075595856\n",
      "Current 840 Step Loss : 0.177796870470047\n",
      "Current 850 Step Loss : 0.30145254731178284\n",
      "Current 860 Step Loss : 0.12553471326828003\n",
      "Current 870 Step Loss : 0.1368078738451004\n",
      "Current 880 Step Loss : 0.16863246262073517\n",
      "Current 890 Step Loss : 0.10754206776618958\n",
      "Current 900 Step Loss : 0.23250554502010345\n",
      "Current 910 Step Loss : 0.12103109061717987\n",
      "Current 920 Step Loss : 0.1373775601387024\n",
      "Current 930 Step Loss : 0.0845392644405365\n",
      "Current 940 Step Loss : 0.22595441341400146\n",
      "Current 950 Step Loss : 0.25399166345596313\n",
      "Current 960 Step Loss : 0.20484724640846252\n",
      "Current 970 Step Loss : 0.12065239250659943\n",
      "Current 980 Step Loss : 0.17233946919441223\n",
      "Current 990 Step Loss : 0.12465829402208328\n",
      "Current 1000 Step Loss : 0.16268032789230347\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9261939778620636\n",
      "Current 1010 Step Loss : 0.19923803210258484\n",
      "Current 1020 Step Loss : 0.1910766363143921\n",
      "Current 1030 Step Loss : 0.057889774441719055\n",
      "Current 1040 Step Loss : 0.1479930430650711\n",
      "Current 1050 Step Loss : 0.12710455060005188\n",
      "Current 1060 Step Loss : 0.16476988792419434\n",
      "Current 1070 Step Loss : 0.08590181171894073\n",
      "Current 1080 Step Loss : 0.33415675163269043\n",
      "Current 1090 Step Loss : 0.14387750625610352\n",
      "Current 1100 Step Loss : 0.10803219676017761\n",
      "Current 1110 Step Loss : 0.343369722366333\n",
      "Current 1120 Step Loss : 0.26082026958465576\n",
      "Current 1130 Step Loss : 0.09962834417819977\n",
      "Current 1140 Step Loss : 0.1552162915468216\n",
      "Current 1150 Step Loss : 0.19119814038276672\n",
      "Current 1160 Step Loss : 0.13949546217918396\n",
      "Current 1170 Step Loss : 0.2461671084165573\n",
      "Current 1180 Step Loss : 0.19002246856689453\n",
      "Current 1190 Step Loss : 0.2770591974258423\n",
      "Current 1200 Step Loss : 0.14924228191375732\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9317671646412261\n",
      "Current 1210 Step Loss : 0.17231206595897675\n",
      "Current 1220 Step Loss : 0.09839705377817154\n",
      "Current 1230 Step Loss : 0.055518537759780884\n",
      "Current 1240 Step Loss : 0.12076499313116074\n",
      "Current 1250 Step Loss : 0.12253938615322113\n",
      "Current 1260 Step Loss : 0.23933236300945282\n",
      "Current 1270 Step Loss : 0.1651296764612198\n",
      "Current 1280 Step Loss : 0.11306309700012207\n",
      "Current 1290 Step Loss : 0.2557337284088135\n",
      "Current 1300 Step Loss : 0.2702263295650482\n",
      "Current 1310 Step Loss : 0.13287176191806793\n",
      "Current 1320 Step Loss : 0.1683623492717743\n",
      "Current 1330 Step Loss : 0.13741683959960938\n",
      "Current 1340 Step Loss : 0.10965201258659363\n",
      "Current 1350 Step Loss : 0.04386642947793007\n",
      "Current 1360 Step Loss : 0.14476986229419708\n",
      "Current 1370 Step Loss : 0.10406897217035294\n",
      "Current 1380 Step Loss : 0.09624093770980835\n",
      "Current 1390 Step Loss : 0.09644848108291626\n",
      "Current 1400 Step Loss : 0.2627621591091156\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9368372165028253\n",
      "Current 1410 Step Loss : 0.2340794950723648\n",
      "Current 1420 Step Loss : 0.10891560465097427\n",
      "Current 1430 Step Loss : 0.13969352841377258\n",
      "Current 1440 Step Loss : 0.16599270701408386\n",
      "Current 1450 Step Loss : 0.22668752074241638\n",
      "Current 1460 Step Loss : 0.15974381566047668\n",
      "Current 1470 Step Loss : 0.057622458785772324\n",
      "Current 1480 Step Loss : 0.14155735075473785\n",
      "Current 1490 Step Loss : 0.24821755290031433\n",
      "Current 1500 Step Loss : 0.14521388709545135\n",
      "Current 1510 Step Loss : 0.13163647055625916\n",
      "Current 1520 Step Loss : 0.06473872065544128\n",
      "Current 1530 Step Loss : 0.11705561727285385\n",
      "Current 1540 Step Loss : 0.16108320653438568\n",
      "Current 1550 Step Loss : 0.21328139305114746\n",
      "Current 1560 Step Loss : 0.1331910341978073\n",
      "Current 1570 Step Loss : 0.0768614262342453\n",
      "Current 1580 Step Loss : 0.14413675665855408\n",
      "Current 1590 Step Loss : 0.12623506784439087\n",
      "Current 1600 Step Loss : 0.23383957147598267\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9414428361328276\n",
      "Current 1610 Step Loss : 0.2146015614271164\n",
      "Current 1620 Step Loss : 0.18757450580596924\n",
      "Current 1630 Step Loss : 0.17877458035945892\n",
      "Current 1640 Step Loss : 0.12845894694328308\n",
      "Current 1650 Step Loss : 0.10937472432851791\n",
      "Current 1660 Step Loss : 0.1545441895723343\n",
      "Current 1670 Step Loss : 0.1651182919740677\n",
      "Current 1680 Step Loss : 0.10382682085037231\n",
      "Current 1690 Step Loss : 0.20387253165245056\n",
      "Current 1700 Step Loss : 0.19741441309452057\n",
      "Current 1710 Step Loss : 0.19005027413368225\n",
      "Current 1720 Step Loss : 0.23204252123832703\n",
      "Current 1730 Step Loss : 0.11483971029520035\n",
      "Current 1740 Step Loss : 0.22408999502658844\n",
      "Current 1750 Step Loss : 0.058690935373306274\n",
      "Current 1760 Step Loss : 0.08867711573839188\n",
      "Current 1770 Step Loss : 0.14497478306293488\n",
      "Current 1780 Step Loss : 0.2696473300457001\n",
      "Current 1790 Step Loss : 0.2028650939464569\n",
      "Current 1800 Step Loss : 0.0764922946691513\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  0\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9430296462574502\n",
      "Current 1810 Step Loss : 0.12306304275989532\n",
      "Current 1820 Step Loss : 0.12743276357650757\n",
      "Current 1830 Step Loss : 0.22629159688949585\n",
      "Current 1840 Step Loss : 0.04522838070988655\n",
      "Current 1850 Step Loss : 0.1897173523902893\n",
      "Current 1860 Step Loss : 0.2505159080028534\n",
      "Current 1870 Step Loss : 0.11698415875434875\n",
      "Current 1880 Step Loss : 0.07980779558420181\n",
      "Current 1890 Step Loss : 0.16717642545700073\n",
      "Current 1900 Step Loss : 0.11089807748794556\n",
      "Current 1910 Step Loss : 0.22634586691856384\n",
      "Current 1920 Step Loss : 0.09154311567544937\n",
      "Current 1930 Step Loss : 0.05401512235403061\n",
      "Current 1940 Step Loss : 0.10422263294458389\n",
      "Current 1950 Step Loss : 0.24143223464488983\n",
      "Current 1960 Step Loss : 0.26364386081695557\n",
      "Current 1970 Step Loss : 0.17371031641960144\n",
      "Current 1980 Step Loss : 0.19945693016052246\n",
      "Current 1990 Step Loss : 0.126418799161911\n",
      "Current 2000 Step Loss : 0.18914030492305756\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9431070516293831\n",
      "Current 2010 Step Loss : 0.08120541274547577\n",
      "Current 2020 Step Loss : 0.17451851069927216\n",
      "Current 2030 Step Loss : 0.25957366824150085\n",
      "Current 2040 Step Loss : 0.0788160040974617\n",
      "Current 2050 Step Loss : 0.2057342827320099\n",
      "Current 2060 Step Loss : 0.11956043541431427\n",
      "Current 2070 Step Loss : 0.1469070017337799\n",
      "Current 2080 Step Loss : 0.139714777469635\n",
      "Current 2090 Step Loss : 0.18193119764328003\n",
      "Current 2100 Step Loss : 0.09751593321561813\n",
      "Current 2110 Step Loss : 0.15771602094173431\n",
      "Current 2120 Step Loss : 0.05452913045883179\n",
      "Current 2130 Step Loss : 0.11510870605707169\n",
      "Current 2140 Step Loss : 0.1464788317680359\n",
      "Current 2150 Step Loss : 0.07960663735866547\n",
      "Current 2160 Step Loss : 0.2177567183971405\n",
      "Current 2170 Step Loss : 0.17414462566375732\n",
      "Current 2180 Step Loss : 0.11460036039352417\n",
      "Current 2190 Step Loss : 0.09051419049501419\n",
      "Current 2200 Step Loss : 0.22203798592090607\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9477513739453518\n",
      "Current 2210 Step Loss : 0.14971758425235748\n",
      "Current 2220 Step Loss : 0.10528380423784256\n",
      "Current 2230 Step Loss : 0.11301608383655548\n",
      "Current 2240 Step Loss : 0.29297059774398804\n",
      "Current 2250 Step Loss : 0.18073420226573944\n",
      "Current 2260 Step Loss : 0.098825603723526\n",
      "Current 2270 Step Loss : 0.11382643133401871\n",
      "Current 2280 Step Loss : 0.08666190505027771\n",
      "Current 2290 Step Loss : 0.0669659674167633\n",
      "Current 2300 Step Loss : 0.12419593334197998\n",
      "Current 2310 Step Loss : 0.16990242898464203\n",
      "Current 2320 Step Loss : 0.07012800872325897\n",
      "Current 2330 Step Loss : 0.13744892179965973\n",
      "Current 2340 Step Loss : 0.22190283238887787\n",
      "Current 2350 Step Loss : 0.1113380491733551\n",
      "Current 2360 Step Loss : 0.19899463653564453\n",
      "Current 2370 Step Loss : 0.06154988706111908\n",
      "Current 2380 Step Loss : 0.15651851892471313\n",
      "Current 2390 Step Loss : 0.09343348443508148\n",
      "Current 2400 Step Loss : 0.20825603604316711\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9453131047294683\n",
      "Current 2410 Step Loss : 0.10871723294258118\n",
      "Current 2420 Step Loss : 0.18682995438575745\n",
      "Current 2430 Step Loss : 0.16076499223709106\n",
      "Current 2440 Step Loss : 0.1225605383515358\n",
      "Current 2450 Step Loss : 0.28122225403785706\n",
      "Current 2460 Step Loss : 0.09049836546182632\n",
      "Current 2470 Step Loss : 0.1334766000509262\n",
      "Current 2480 Step Loss : 0.15983593463897705\n",
      "Current 2490 Step Loss : 0.049688421189785004\n",
      "Current 2500 Step Loss : 0.1376696676015854\n",
      "Current 2510 Step Loss : 0.0943070501089096\n",
      "Current 2520 Step Loss : 0.32184916734695435\n",
      "Current 2530 Step Loss : 0.09402620047330856\n",
      "Current 2540 Step Loss : 0.16660407185554504\n",
      "Current 2550 Step Loss : 0.20919759571552277\n",
      "Current 2560 Step Loss : 0.20843829214572906\n",
      "Current 2570 Step Loss : 0.15654730796813965\n",
      "Current 2580 Step Loss : 0.27003368735313416\n",
      "Current 2590 Step Loss : 0.11002431809902191\n",
      "Current 2600 Step Loss : 0.1678234338760376\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9475191578295533\n",
      "Current 2610 Step Loss : 0.11521730571985245\n",
      "Current 2620 Step Loss : 0.1922982633113861\n",
      "Current 2630 Step Loss : 0.2038831263780594\n",
      "Current 2640 Step Loss : 0.10345406085252762\n",
      "Current 2650 Step Loss : 0.10741689056158066\n",
      "Current 2660 Step Loss : 0.1425628960132599\n",
      "Current 2670 Step Loss : 0.09579841047525406\n",
      "Current 2680 Step Loss : 0.14860163629055023\n",
      "Current 2690 Step Loss : 0.091550312936306\n",
      "Current 2700 Step Loss : 0.04289694502949715\n",
      "Current 2710 Step Loss : 0.0816270187497139\n",
      "Current 2720 Step Loss : 0.09678201377391815\n",
      "Current 2730 Step Loss : 0.1455010026693344\n",
      "Current 2740 Step Loss : 0.18884891271591187\n",
      "Current 2750 Step Loss : 0.16135916113853455\n",
      "Current 2760 Step Loss : 0.15283235907554626\n",
      "Current 2770 Step Loss : 0.12052972614765167\n",
      "Current 2780 Step Loss : 0.12558753788471222\n",
      "Current 2790 Step Loss : 0.1242174282670021\n",
      "Current 2800 Step Loss : 0.12302990257740021\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9461258611347627\n",
      "Current 2810 Step Loss : 0.1424844115972519\n",
      "Current 2820 Step Loss : 0.2159150242805481\n",
      "Current 2830 Step Loss : 0.059979457408189774\n",
      "Current 2840 Step Loss : 0.06915903091430664\n",
      "Current 2850 Step Loss : 0.0803188607096672\n",
      "Current 2860 Step Loss : 0.09216099977493286\n",
      "Current 2870 Step Loss : 0.14382238686084747\n",
      "Current 2880 Step Loss : 0.09594994783401489\n",
      "Current 2890 Step Loss : 0.1280365288257599\n",
      "Current 2900 Step Loss : 0.16063928604125977\n",
      "Current 2910 Step Loss : 0.11674968898296356\n",
      "Current 2920 Step Loss : 0.15716657042503357\n",
      "Current 2930 Step Loss : 0.10656315833330154\n",
      "Current 2940 Step Loss : 0.08177392929792404\n",
      "Current 2950 Step Loss : 0.09870591014623642\n",
      "Current 2960 Step Loss : 0.1294097602367401\n",
      "Current 2970 Step Loss : 0.08329513669013977\n",
      "Current 2980 Step Loss : 0.1475651115179062\n",
      "Current 2990 Step Loss : 0.10532581061124802\n",
      "Current 3000 Step Loss : 0.11585443466901779\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.946435482622494\n",
      "Current 3010 Step Loss : 0.19191475212574005\n",
      "Current 3020 Step Loss : 0.15485186874866486\n",
      "Current 3030 Step Loss : 0.12014850974082947\n",
      "Current 3040 Step Loss : 0.1031707301735878\n",
      "Current 3050 Step Loss : 0.05709998682141304\n",
      "Current 3060 Step Loss : 0.14304645359516144\n",
      "Current 3070 Step Loss : 0.06524556130170822\n",
      "Current 3080 Step Loss : 0.1839989274740219\n",
      "Current 3090 Step Loss : 0.05265633016824722\n",
      "Current 3100 Step Loss : 0.08024252951145172\n",
      "Current 3110 Step Loss : 0.0827271044254303\n",
      "Current 3120 Step Loss : 0.09760616719722748\n",
      "Current 3130 Step Loss : 0.18935690820217133\n",
      "Current 3140 Step Loss : 0.11026240140199661\n",
      "Current 3150 Step Loss : 0.10639575123786926\n",
      "Current 3160 Step Loss : 0.14119842648506165\n",
      "Current 3170 Step Loss : 0.06911271810531616\n",
      "Current 3180 Step Loss : 0.08628296107053757\n",
      "Current 3190 Step Loss : 0.07230047136545181\n",
      "Current 3200 Step Loss : 0.09073158353567123\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  인천지역에\n",
      "Queue Bottom :  11층\n",
      "Queue :  이상 고층 건축물은 아파트 3887개동과 일반 건축물 등 총 4064개동이다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  이 사전은 해당 단어와 같은 의미로\n",
      "Stack Top :  사용되는\n",
      "Queue Bottom :  동의어까지\n",
      "Queue :  함께 찾아준다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  아시아 경제위기 , 외환위기가 발생한 직후에도\n",
      "Stack Top :  그는\n",
      "Queue Bottom :  경고를\n",
      "Queue :  날렸다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  \n",
      "Stack Top :  그는\n",
      "Queue Bottom :  있는\n",
      "Queue :  만큼 이 문제만 극복된다면 한국의 투자 매력도는 굉장히 올라갈 것 ” 이라고 덧붙였다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  한화 측은 “ 자금 조달 계획에 최대한 성의를 보였는데 산은은 수정안에 대해 자산가격을 조정하는 등의 협상도 하지 않은 채 일방적으로 공문만\n",
      "Stack Top :  보냈다 ” 며\n",
      "Queue Bottom :  팔\n",
      "Queue :  의지가 있는지 의심스럽다 ” 고 말했다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  맨살이 드러나는 건 얼굴밖에\n",
      "Stack Top :  없지만\n",
      "Queue Bottom :  선수들의\n",
      "Queue :  건강미를 감상한다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  “ 두딸이 ‘ 돌아올수\n",
      "Stack Top :  없는\n",
      "Queue Bottom :  문 ’\n",
      "Queue :  오가는 모습 못잊어 ”\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  北 개성관광만 빼고 ‘ 12 · 1조치 ’\n",
      "Stack Top :  모두\n",
      "Queue Bottom :  철회\n",
      "Queue :  \n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  20세 이하 월드컵에서 18년 만의 8강 진출이란 성과를 냈기에\n",
      "Stack Top :  굳이\n",
      "Queue Bottom :  없다는\n",
      "Queue :  판단이다 .\n",
      "Prediction :  1\n",
      "Label :  1 \n",
      "\n",
      "\n",
      "\n",
      "Stack :  교육과학기술부 산하 ‘ 교육사이버안전센터 ( ECSC ) ’ 는 “ ( 국정원 산하 ) NCSC를 사칭한 해킹 e메일이 공공기관 등에 유포되고\n",
      "Stack Top :  있다 ” 며\n",
      "Queue Bottom :  내용을\n",
      "Queue :  공지한 것으로 3일 확인됐다 .\n",
      "Prediction :  0\n",
      "Label :  0 \n",
      "\n",
      "\n",
      "Accuracy : 0.9482932115488815\n",
      "Current 3210 Step Loss : 0.103635773062706\n",
      "Current 3220 Step Loss : 0.05472187697887421\n",
      "Current 3230 Step Loss : 0.2427055388689041\n",
      "Current 3240 Step Loss : 0.04929954186081886\n",
      "Current 3250 Step Loss : 0.1382547914981842\n",
      "Current 3260 Step Loss : 0.10332417488098145\n",
      "Current 3270 Step Loss : 0.056622214615345\n",
      "Current 3280 Step Loss : 0.05564667284488678\n",
      "Current 3290 Step Loss : 0.052289217710494995\n",
      "Current 3300 Step Loss : 0.06210816651582718\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, SequentialSampler, TensorDataset)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if (__name__ == \"__main__\"):\n",
    "    output_dir = os.path.join(root_dir, \"output\")\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    set_seed(seed=1234)\n",
    "\n",
    "    config = {\"mode\": \"train\",\n",
    "              \"train_data_path\": os.path.join(root_dir, \"train.txt\"),\n",
    "              \"test_data_path\": os.path.join(root_dir, \"test.txt\"),\n",
    "              \"output_dir_path\": output_dir,\n",
    "              \"pretrained_model_name_or_path\": \"monologg/koelectra-small-v3-discriminator\",\n",
    "              \"label_vocab_data_path\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
    "              \"num_labels\": 2,\n",
    "              \"max_length\": 250,\n",
    "              \"epoch\": 10,\n",
    "              \"batch_size\": 64,\n",
    "              }\n",
    "\n",
    "    if (config[\"mode\"] == \"train\"):\n",
    "        train(config)\n",
    "    elif config[\"mode\"] == 'test':\n",
    "        tokenizer = ElectraTokenizer.from_pretrained(config[\"pretrained_model_name_or_path\"])\n",
    "        electra_config = ElectraConfig.from_pretrained(config[\"output_dir_path\"])\n",
    "        model = ElectraForSequenceClassification.from_pretrained(config[\"output_dir_path\"], config=electra_config).cuda()\n",
    "        evaluate(model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D257Phc0-5gy"
   },
   "source": [
    "# 새 섹션"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1X8mATJhAFxIGz7hTUWrII71scpzkSa04",
   "authorship_tag": "ABX9TyOTxpNjqIq5u9NEV5bvxjJ9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f50e35cc8a37407d88814d70ba9cb487": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7528e4c76be642558b04acfbd2cbb165",
       "IPY_MODEL_1d4427f19e764a2a8bc8e88ed65096cb",
       "IPY_MODEL_bb1e938ba46447e5a8cfe4cd53150664"
      ],
      "layout": "IPY_MODEL_b0f9eebff31d4a5f97541531879d9711"
     }
    },
    "7528e4c76be642558b04acfbd2cbb165": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_553d0efd6ecf4b6cad71ebef8784fc87",
      "placeholder": "​",
      "style": "IPY_MODEL_c5c9283cfe98451980477cae8330e129",
      "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
     }
    },
    "1d4427f19e764a2a8bc8e88ed65096cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8668b8e5b3d745bf90d6561d792d4311",
      "max": 5.6577499E7,
      "min": 0.0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8722a710d71849488569792395df47bf",
      "value": 5.6577499E7
     }
    },
    "bb1e938ba46447e5a8cfe4cd53150664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76642ecf0f5645369e38ad63abe05022",
      "placeholder": "​",
      "style": "IPY_MODEL_c821f8fe10034a7dac55b362f1bffd39",
      "value": " 56.6M/56.6M [00:01&lt;00:00, 35.1MB/s]"
     }
    },
    "b0f9eebff31d4a5f97541531879d9711": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553d0efd6ecf4b6cad71ebef8784fc87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5c9283cfe98451980477cae8330e129": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8668b8e5b3d745bf90d6561d792d4311": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8722a710d71849488569792395df47bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76642ecf0f5645369e38ad63abe05022": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c821f8fe10034a7dac55b362f1bffd39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
