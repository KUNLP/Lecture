{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"electra_mrc.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2H9Lzinh29v","executionInfo":{"status":"ok","timestamp":1623377581595,"user_tz":-540,"elapsed":17695,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"6df130d9-c1a8-4151-f694-5a0320a31f4f"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8XApV-CmzxD","executionInfo":{"status":"ok","timestamp":1623377592928,"user_tz":-540,"elapsed":8364,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"1956f479-8f5b-4835-a429-73b88e77f08a"},"source":["!pip install tokenizers\n","!pip install transformers==2.11.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tokenizers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 8.7MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.10.3\n","Collecting transformers==2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 8.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (20.9)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/59/bb06dd5ca53547d523422d32735585493e0103c992a52a97ba3aa3be33bf/tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n","\u001b[K     |████████████████████████████████| 5.6MB 11.1MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 49.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 42.7MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","  Found existing installation: tokenizers 0.10.3\n","    Uninstalling tokenizers-0.10.3:\n","      Successfully uninstalled tokenizers-0.10.3\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.7.0 transformers-2.11.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dvfZSi_iCFk"},"source":["import sys\n","sys.path.append(\"/gdrive/MyDrive/colab/transfer_learn/mrc\")\n","from tokenization_kocharelectra import KoCharElectraTokenizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tyva6v9ZmSdp"},"source":["import torch\n","import numpy as np\n","import os\n","\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from transformers.configuration_electra import ElectraConfig\n","from transformers.modeling_electra import ElectraPreTrainedModel, ElectraModel\n","from transformers.optimization import AdamW\n","\n","from tokenization_kocharelectra import KoCharElectraTokenizer\n","\n","class ElectraMRC(ElectraPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        # 분류할 라벨의 개수\n","        self.num_labels = config.num_labels\n","\n","        # ELECTRA 모델\n","        self.electra = ElectraModel(config)\n","\n","        # Span 범위 예측을 위한 linear\n","        self.projection_layer = nn.Linear(config.hidden_size, self.num_labels)\n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n","        # input_ids, attention_mask, token_type_ids 형태: [batch, seq_len]\n","        # electra_outputs 형태: [1, batch, seq_len, hidden]\n","        electra_outputs = self.electra(input_ids, attention_mask, token_type_ids)\n"," \n","        # hypothesis 형태: [batch, seq_len, 2 (start/end)]\n","        hypothesis = self.projection_layer(electra_outputs[0])\n","\n","        # start, end 형태: [batch, seq_len, 1] -> [batch, seq_len]\n","        p_start, p_end = hypothesis.split(1, dim=-1)\n","        p_start = p_start.squeeze(-1)\n","        p_end = p_end.squeeze(-1)\n"," \n","        return p_start, p_end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRWJIqTSm_sY"},"source":["\n","def convert_data2feature(config, input_sequence, tokenizer):\n","    # input_sequence : [CLS] Question [SEP] Context [SEP]\n","    # => [CLS] 세 종 대 왕 은 _ 몇 _ 대 _ 왕 인 가 ? [SEP] 세 종 대 왕 은 _ 조 선 의 _ ~ [SEP]\"\n","\n","    # 고정 길이 벡터 생성\n","    input_ids = np.zeros(config[\"max_length\"], dtype=np.int)\n","    attention_mask = np.zeros(config[\"max_length\"], dtype=np.int)\n","    segment_ids = np.zeros(config[\"max_length\"], dtype=np.int)\n","\n","    is_context = False\n","    for idx, token in enumerate(input_sequence.split()):\n","        input_ids[idx] = tokenizer._convert_token_to_id(token)\n","        attention_mask[idx] = 1\n","        if is_context:\n","            segment_ids[idx] = 1\n","        if token == '[SEP]':\n","            is_context = True\n","\n","    return input_ids, attention_mask, segment_ids\n","\n","# 데이터 읽기 함수\n","def read_data(file_path, tokenizer):\n","    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n","        lines = inFile.readlines()\n","\n","    # 데이터를 저장하기 위한 리스트 생성\n","    all_input_ids, all_attention_mask, all_segment_ids, start_indexes, end_indexes = [], [], [], [], []\n","    for idx, line in enumerate(lines):\n","        input_sequence, start_idx, end_idx = line.strip().split(\"\\t\")\n","        input_ids, attention_mask, segment_ids = convert_data2feature(config, input_sequence, tokenizer)\n","\n","        all_input_ids.append(input_ids)\n","        all_attention_mask.append(attention_mask)\n","        all_segment_ids.append(segment_ids)\n","        start_indexes.append(int(start_idx))\n","        end_indexes.append(int(end_idx))\n","\n","    all_input_ids = torch.tensor(all_input_ids, dtype=torch.long)\n","    all_attention_mask = torch.tensor(all_attention_mask, dtype=torch.long)\n","    all_segment_ids = torch.tensor(all_segment_ids, dtype=torch.long)\n","    start_indexes = torch.tensor(start_indexes, dtype=torch.long)\n","    end_indexes = torch.tensor(end_indexes, dtype=torch.long)\n","\n","    return all_input_ids, all_attention_mask, all_segment_ids, start_indexes, end_indexes\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eH5L3vM3ncRN"},"source":["\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","def do_test(model, tokenizer):\n","    # 평가 모드 셋팅\n","    model.eval()\n","\n","    # 평가 데이터 Load\n","    all_input_ids, all_attention_mask, all_segment_ids, start_indexes, end_indexes = \\\n","        read_data(tokenizer=tokenizer, file_path=config[\"test_data_path\"])\n","\n","    # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n","    test_features = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, start_indexes, end_indexes)\n","    test_dataloader = DataLoader(test_features, shuffle = True, batch_size=1)\n","\n","    for step, batch in enumerate(test_dataloader):\n","        batch = tuple(t.cuda() for t in batch)\n","        input_ids, attention_mask, segment_ids, a_start, a_end = batch\n","\n","        # 입력 데이터에 대한 출력과 loss 생성\n","        # p_start, p_end 형태:[1, seq_len]\n","        p_start, p_end = model(input_ids, attention_mask, segment_ids)\n","  \n","        p_start = p_start.argmax(dim=-1)\n","        p_start = tensor2list(p_start)[0]\n","        p_end = p_end.argmax(dim=-1)\n","        p_end_ = tensor2list(p_end)[0]\n","\n","        a_start = tensor2list(a_start)[0]\n","        a_end = tensor2list(a_end)[0]\n","\n","        # 입력 Text 생성\n","        input_token_ids = tensor2list(input_ids)[0]\n","        input_tokens = [tokenizer._convert_id_to_token(e) for e in input_token_ids]\n","\n","        # 입력 Text에서 예측/정답 Span 추출\n","        predict_span = input_tokens[p_start:p_end+1]\n","        answer_span = input_tokens[a_start:a_end+1]\n","\n","        # 입력 Seqquence의 질문, 단락 위치 저장\n","        segment_positions = [position for position, token in enumerate(input_tokens) if token == \"[SEP]\"]\n","\n","        # 모델 예측 확인\n","        if step < 5:\n","            question = ''.join(input_tokens[1:segment_positions[0]]).replace(\"_\", \" \")\n","            context = ''.join(input_tokens[segment_positions[0] + 1:segment_positions[1]]).replace(\"_\", \" \")\n","            print(\"\\n\\n######################################\")\n","            print(\"Context : \", context)\n","            print(\"Question : \", question)\n","            print(\"Answer Span : \", ''.join(predict_span).replace(\"_\", \" \"))\n","            print(\"Predict Span : \", ''.join(answer_span).replace(\"_\", \" \"))\n","        else:\n","            break\n","\n","def test(config):\n","    # electra config 객체 생성\n","    electra_config = ElectraConfig.from_pretrained(\n","        os.path.join(config[\"output_dir\"], \"checkpoint-{0:d}\".format(config[\"checkpoint\"])),\n","        num_labels=config[\"num_labels\"])\n","\n","    # electra tokenizer 객체 생성\n","    electra_tokenizer = KoCharElectraTokenizer.from_pretrained(\n","        os.path.join(config[\"output_dir\"], \"checkpoint-{0:d}\".format(config[\"checkpoint\"])),\n","        do_lower_case=False)\n","\n","    # electra model 객체 생성\n","    model = ElectraMRC.from_pretrained(\n","        os.path.join(config[\"output_dir\"], \"checkpoint-{0:d}\".format(config[\"checkpoint\"])),\n","        config=electra_config).cuda()\n","\n","    do_test(model=model, tokenizer=electra_tokenizer)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_43Pk3WnebQ"},"source":["\n","def train(config):\n","    # electra config 객체 생성\n","    electra_config = ElectraConfig.from_pretrained(\"monologg/kocharelectra-base-discriminator\",\n","                                                   num_labels=config[\"num_labels\"])\n","    # electra tokenizer 객체 생성\n","    electra_tokenizer = KoCharElectraTokenizer.from_pretrained(\"monologg/kocharelectra-base-discriminator\",\n","                                                               do_lower_case=False)\n","    # electra model 객체 생성\n","    model = ElectraMRC.from_pretrained(\"monologg/kocharelectra-base-discriminator\",\n","                                                                     config=electra_config).cuda()\n","    # 데이터 읽기\n","    all_input_ids, all_attention_mask, all_token_type_ids, start_indexes, end_indexes = \\\n","        read_data(tokenizer=electra_tokenizer, file_path=config[\"train_data_path\"])\n","\n","    # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n","    train_features = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, start_indexes, end_indexes)\n","    train_dataloader = DataLoader(train_features, batch_size=config[\"batch_size\"])\n","\n","    # 크로스 엔트로피 손실 함수\n","    loss_func = nn.CrossEntropyLoss()\n","\n","    # 옵티마이저 함수 지정\n","    optimizer = AdamW(model.parameters(), lr=config[\"learning_rate\"])\n","\n","    for epoch in range(config[\"epoch\"]):\n","        for step, batch in enumerate(train_dataloader):\n","            # 학습 모드 셋팅\n","            model.train()\n","            # batch = (input_ids[step], attention_mask[step], segment_ids[step],\n","            #                                    start_index[step], end_index[step])*batch_size\n","            # .cuda()를 통해 메모리에 업로드\n","            batch = tuple(t.cuda() for t in batch)\n","\n","            # 변화도를 0으로 변경\n","            optimizer.zero_grad()\n","\n","            # p_start, p_end 형식: [batch, seq_len]\n","            # a_start, a_end 형식: [batch]\n","            input_ids, attention_mask, segment_ids, a_start, a_end = batch\n","            p_start, p_end = model(input_ids, attention_mask, segment_ids)\n","\n","            start_loss = loss_func(p_start, a_start)\n","            end_loss = loss_func(p_end, a_end)\n","\n","            total_loss = start_loss + end_loss\n","\n","            # 손실 역전파 수행\n","            total_loss.backward()\n","            optimizer.step()\n","\n","            # 50 batch_step 마다 Loss 출력\n","            if (step + 1) % 50 == 0:\n","                print(\"Current Step : {0:d} / {1:d}\\tCurrent Loss : {2:.4f}\".format(step+1, int(len(all_input_ids) / config['batch_size']), total_loss.item()))\n","\n","            # 500 batch_step 마다 결과 출력\n","            if (step + 1) % 500 == 0:\n","                do_test(model, electra_tokenizer)\n","\n","        # 에폭마다 가중치 저장\n","        output_dir = os.path.join(config[\"output_dir\"], \"checkpoint-{}\".format(epoch+1))\n","        if not os.path.exists(output_dir):\n","            os.makedirs(output_dir)\n","\n","        electra_config.save_pretrained(output_dir)\n","        electra_tokenizer.save_pretrained(output_dir)\n","        model.save_pretrained(output_dir)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYKbMZ1nnnPS","executionInfo":{"status":"ok","timestamp":1623378281744,"user_tz":-540,"elapsed":4616,"user":{"displayName":"Harksoo Kim","photoUrl":"","userId":"04506968767642445103"}},"outputId":"10a03df3-6fb0-44bc-c3fa-9a8e38b607de"},"source":["if __name__ == \"__main__\":\n","    root_dir = \"/gdrive/MyDrive/colab/transfer_learn/mrc\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","\n","    if (not os.path.exists(output_dir)):\n","        os.makedirs(output_dir)\n","\n","    config = {\"mode\": \"test\",\n","              \"train_data_path\": os.path.join(root_dir, \"mrc_train.txt\"),\n","              \"test_data_path\": os.path.join(root_dir, \"mrc_dev.txt\"),\n","              \"output_dir\": output_dir,\n","              \"checkpoint\": 3,\n","              \"epoch\": 3,\n","              \"learning_rate\": 5e-5,\n","              \"batch_size\": 16,\n","              \"max_length\": 512,\n","              \"num_labels\": 2,\n","              }\n","\n","    if (config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","######################################\n","Context :  2008년 2월 25일 이명박은 취임식과 함께 업무 수행을 시작했다. 새 정부의 이름은 각 정권마다 추구하는 핵심 가치를 담아 정권의 이름을 사용한 전 정부들과는 달리 대통령의 실명을 공식적으로 정권 이름에 사용하게 되었다(이것이 첫 사례였다). 이명박 대통령이 17대 대선 후보로 활동하던 당시에 강조하였던 '창조적 실용주의'를 반영하여 간혹 실용정부([UNK][UNK][UNK][UNK])라는 명칭이 사용되기도 한다. 그리고 인수위원회에서는 작은정부 구축을 위해 정부조직을 대대적으로 통폐합하여 개편안을 발표했다. 주 목표는 '작은 정부, 큰 시장'을 큰 뼈대로 '경제살리기'가 목표였다. 한편 이명박 정부 출범의 뒤를 이어 총선거가 치러졌는데, 이 선거에서 여당인 한나라당이 최다 의석을 차지했다.\n","Question :  이명박이 취임식과 함께 업무수행을 시작한 해는?\n","Answer Span :  2008년\n","Predict Span :  2008년\n","\n","\n","######################################\n","Context :  부모는 사건 이후 일을 그만두고 딸의 치료에만 매달렸다. 안산시에서 지원금을 받아 병원비와 각종 경비를 부담하고 있었다. 보험사도 끔찍한 사고를 감안해 4000만 원의 보험금을 지급했다. 그러자 안산시는 시에서 받은 긴급치료지원비 600만 원을 모두 반납하라고 명령하면서 만일 이행하지 않을 경우 전세금을 압류하겠다고 안산시장 명의의 공문을 지난 2009년 6월 발송하였다. 또 생활보호대상자 혜택도 중단한다고 통보했다. “원칙적으로 통장에 300만 원 이상의 잔고가 있으면 지원대상에서 제외된다\"는 이유였다. 부모는 딸의 신체 중 일부 기능이 영구 상실됐고 앞으로 몇 년은 더 심리치료를 받아야 한다고 사정했으나 받아들여지지 않았다.\n","Question :  조두순 사건에서 보험사는 부모에게 얼마를 지급했는가?\n","Answer Span :  4000만 원\n","Predict Span :  4000만 원\n","\n","\n","######################################\n","Context :  천문학적으로는, 정월 대보름은 \"[UNK]보름\"이 아닐 수도 있다. 보름달은 한 달에 한 번 뜨게 되는데, 정월 대보름에 뜨는 보름달이 가장 크려면, 그 때, 보름달이 지구에서 가장 가까워야 한다. 그러나 정월 대보름에 뜨는 보름달이 지구에서 가장 가까울 때도 있지만, 가장 멀 때도 있다. 그래서 정월 대보름은 \"[UNK]보름\"이 아닐 수도 있다. 음력 새해를 시작하고 맞이하는 첫 번째 보름달이기에 \"[UNK]보름\"이라고 부르는 것일 뿐이다. 이와 마찬가지로, 추석에 가장 큰 보름달이 아닐 수도 있다. 참고로, 보름달이 가장 클 때를 슈퍼문이라고 한다./설날(새날)을 맞이하고 첫 번째 보름달이기에 대보름 즉, 큰 보름이라는 의미가 있다고 본다. 큰 형(맏형,[UNK][UNK],중국식 표기), 큰 아버지, 큰 할아버지처럼 이 대([UNK])를 큰,맏이의 의미로 새해 첫 보름달로써 농사의 시작일을 의미하는 날로 볼 수 있겠다.\n","Question :  보름달이 뜨는 주기는?\n","Answer Span :  한 달\n","Predict Span :  한 달에 한 번\n","\n","\n","######################################\n","Context :  2006년 은평뉴타운의 고분양가가 논란이 되자 오세훈 시장은 서울시가 건설하는 모든 아파트에 대해 건설 공정이 80% 이상 진행된 이후에 분양하는 ‘아파트 후분양제’를 도입하였다. 2007년 신년사를 통해 “서울시 SH공사가 공급하는 아파트의 50여 개에 달하는 항목의 분양원가를 상세히 공개하고 자치구 분양승인에 대해서도 새로운 기준을 만들어 분양가격을 판단할 근거를 마련하겠다”며 투명한 분양원가 공개를 천명했다. 이는 참여정부의 부동산정책 혼선과 부동산가격 폭등 현상에 극명히 대비되어 주목받았고, 이에 경제정의실천시민연합 김헌동 아파트값 거품빼기 운동본부장은 '노무현 대통령보다 오세훈 시장이 훨씬 월등한 정책을 쓰고 있다'라고 논평하였다.\n","Question :  오세훈이 2007년 신년사를 통해 천명한것은?\n","Answer Span :  분양원가 공개\n","Predict Span :  투명한 분양원가 공개\n","\n","\n","######################################\n","Context :  기록된 과학 연구로서 가장 오래된 것은 동북아프리카의 이집트에서 찾을 수 있다. 러시아 태생의 미국인 작가 아이작 아시모프는 그의 책 《과학과 기술의 인명 백과사전》에서 과학은 고대 아프리카가 현대 세계에 준 선물이라고 말한다. 이집트의 성직자 임호테프는 처음으로 약을 조제한 사람으로 알려져 있다. 이집트의 알렉산드리아 도서관은 최초의 대규모 과학 연구소라 할 수 있는데, 유클리드와 알렉산드리아의 헤론을 비롯해 고대의 주요 과학자들 중 많은 수가 여기에서 연구를 했다. 이집트의 뒤를 이어, 고대 그리스에서도 많은 과학적 발견들이 이루어졌다. 그 이후 이슬람 문화권에서도 과학에 대한 발전이 있었으며, 산업 혁명 후 과학에 대한 많은 발전이 있었다. 또한, 동양에서는 주판을 비롯한 계산기가 발견되고 화약 등이 발명되면서 과학이 발전해 나갔다.\n","Question :  미국인 작가 아이작 아시모프가 태어난 곳은?\n","Answer Span :  러시아\n","Predict Span :  러시아\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"INC2ghKPR3za"},"source":[""],"execution_count":null,"outputs":[]}]}